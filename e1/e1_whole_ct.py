from sqlalchemy import create_engine, text
import pandas as pd
import numpy as np
from datetime import timedelta, time, datetime
import time as time_mod
from concurrent.futures import ProcessPoolExecutor
import os
import webbrowser

import plotly.express as px
import plotly.io as pio


# ===========================
# ì „ì—­ ì„¤ì •
# ===========================
DB_CONFIG = {
    "host": "100.105.75.47",
    "port": 5432,
    "dbname": "postgres",
    "user": "postgres",
    "password": "leejangwoo1!",
}

# ë¶€íŠ¸ìŠ¤íŠ¸ë© ë°˜ë³µ íšŸìˆ˜
N_BOOTSTRAP = 10

# ì‹ ë¢°êµ¬ê°„ (%). 95.0 â†’ 95% CI, 99.0 â†’ 99% CI
CI_LEVEL = 95.0  # â˜… ì—¬ê¸°ë§Œ ë°”ê¾¸ë©´ ì „ì²´ CI ë³€ê²½

# ë¶€íŠ¸ìŠ¤íŠ¸ë© ë©€í‹°í”„ë¡œì„¸ì‹± ì›Œì»¤ ìˆ˜
N_BOOTSTRAP_WORKERS = 2

# ê·¸ë˜í”„ HTML ì €ì¥ í´ë” / íŒŒì¼
PLOT_DIR = "./plots"
PLOT_FILE = "vision_dashboard.html"

# ë£¨í”„ ì£¼ê¸° (ì´ˆ)
LOOP_INTERVAL_SEC = 1.0

# ì´ì „ ê²°ê³¼ ìºì‹œ: {month: {remark: ct}}
LAST_RESULT = {}

# ë¸Œë¼ìš°ì € ìµœì´ˆ ì˜¤í”ˆ ì—¬ë¶€
FIRST_OPEN = True


# ===========================
# ê³µí†µ ìœ í‹¸
# ===========================
def get_engine():
    url = (
        f"postgresql+psycopg2://{DB_CONFIG['user']}:{DB_CONFIG['password']}@"
        f"{DB_CONFIG['host']}:{DB_CONFIG['port']}/{DB_CONFIG['dbname']}"
    )
    return create_engine(url)


def ensure_plot_dir():
    if not os.path.exists(PLOT_DIR):
        os.makedirs(PLOT_DIR, exist_ok=True)


# ===========================
# 1. VIEWì—ì„œ ë°ì´í„° ë¡œë“œ
# ===========================
def load_data(engine: create_engine) -> pd.DataFrame:
    query = """
        SELECT
            id,
            station,
            remark,
            barcode_information,
            end_day,
            end_time,
            ct,
            file_path
        FROM a2_fct_vision_testlog_json_processing.v_vision_pass_ct
        ORDER BY station, end_day, end_time;
    """
    df = pd.read_sql_query(query, engine)
    print("\n[STEP 1] RAW DATA (ì• 5í–‰)")
    print(df.head().to_string(index=False))
    return df


# ===========================
# 1-1. ê¸°ì¡´ clean ë°ì´í„° ë¡œë“œ / ì‹ ê·œ clean ì €ì¥ (processing í…Œì´ë¸”)
# ===========================
def load_processed_clean(engine: create_engine) -> pd.DataFrame:
    """
    e1_whole_ct.processing ì— ì €ì¥ëœ 'ì´ë¯¸ ì²˜ë¦¬ëœ clean ë°ì´í„°'ë¥¼ ì½ì–´ì˜¨ë‹¤.
    ì—†ìœ¼ë©´ ë¹ˆ DataFrame ë°˜í™˜.
    """
    with engine.begin() as conn:
        conn.execute(text("CREATE SCHEMA IF NOT EXISTS e1_whole_ct;"))
        conn.execute(text("""
            CREATE TABLE IF NOT EXISTS e1_whole_ct.processing (
                id                  bigint,
                station             varchar(50),
                remark              varchar(20),
                barcode_information text,
                ct                  numeric,
                end_day             date,
                end_time            time,
                shift               varchar(10),
                shift_date          date,
                file_path           text,
                PRIMARY KEY (station, remark, file_path)
            );
        """))
        df_old = pd.read_sql_query(
            """
            SELECT
                id, station, remark, barcode_information, ct,
                end_day, end_time, shift, shift_date, file_path
            FROM e1_whole_ct.processing
            """,
            conn,
        )
    return df_old


def save_new_clean(engine, df):
    print("[DEBUG] save_new_clean() í˜¸ì¶œë¨ â€” row ìˆ˜:", len(df))

    if df.empty:
        print("[DEBUG] df ë¹„ì–´ìˆìŒ â€” INSERT ìŠ¤í‚µ")
        return

    # INSERTì— í•„ìš”í•œ ì»¬ëŸ¼ë§Œ ì„ íƒ
    required_cols = ["station", "remark", "barcode_information", "ct",
                     "end_day", "end_time", "shift", "shift_date", "file_path"]

    missing = [c for c in required_cols if c not in df.columns]
    print("[DEBUG] ëˆ„ë½ëœ ì»¬ëŸ¼:", missing)

    if missing:
        print("[ERROR] INSERT ì‹¤íŒ¨ â€” ì»¬ëŸ¼ì´ ë¶€ì¡±í•¨")
        return

    # ğŸ”¥ TEST INSERT (ì‹¤ì œ commit í¬í•¨)
    try:
        with engine.begin() as conn:
            df[required_cols].to_sql(
                "processing",
                con=conn,
                schema="e1_whole_ct",
                if_exists="append",
                index=False,
                method="multi",
            )
        print("[DEBUG] INSERT ì„±ê³µ!")
    except Exception as e:
        print("[ERROR] INSERT ì¤‘ ì˜¤ë¥˜:", e)

# ===========================
# 2. ì£¼/ì•¼ê°„ + shift_date ê³„ì‚°
# ===========================
def add_shift_info(df: pd.DataFrame) -> pd.DataFrame:
    df2 = df.copy()

    df2["end_day"] = df2["end_day"].astype(str).str.strip()
    df2["end_time"] = df2["end_time"].astype(str).str.strip()
    df2["end_dt"] = pd.to_datetime(
        df2["end_day"] + " " + df2["end_time"],
        format="%Y-%m-%d %H:%M:%S"
    )

    df2["shift"] = "Day"
    df2["shift_date"] = df2["end_dt"].dt.date

    t = df2["end_dt"].dt.time

    t_day_start = time(8, 30, 0)
    t_day_end = time(20, 29, 59)
    t_night_start = time(20, 30, 0)
    t_night_morning_end = time(8, 29, 59)

    # ì£¼ê°„
    cond_day = (t >= t_day_start) & (t <= t_day_end)
    df2.loc[cond_day, "shift"] = "Day"
    df2.loc[cond_day, "shift_date"] = df2.loc[cond_day, "end_dt"].dt.date

    # ì•¼ê°„ (ì €ë…)
    cond_night_evening = (t >= t_night_start)
    df2.loc[cond_night_evening, "shift"] = "Night"
    df2.loc[cond_night_evening, "shift_date"] = df2.loc[cond_night_evening, "end_dt"].dt.date

    # ì•¼ê°„ (ìƒˆë²½) â†’ ì „ë‚  ì•¼ê°„
    cond_night_morning = (t <= t_night_morning_end)
    df2.loc[cond_night_morning, "shift"] = "Night"
    df2.loc[cond_night_morning, "shift_date"] = (
        df2.loc[cond_night_morning, "end_dt"] - timedelta(days=1)
    ).dt.date

    print("\n[STEP 2] SHIFT INFO (ì• 10í–‰)")
    print(df2[["id", "station", "remark", "end_day", "end_time", "shift", "shift_date"]]
          .head(10).to_string(index=False))
    return df2


# ===========================
# 3. IQR ì´ìƒì¹˜ ì œê±° (â˜… ê¸°ì¡´ + processed_keys ì ìš© ë²„ì „)
# ===========================
def detect_outliers_iqr(series: pd.Series):
    q1 = series.quantile(0.25)
    q3 = series.quantile(0.75)
    iqr = q3 - q1
    lower = q1 - 1.5 * iqr
    upper = q3 + 1.5 * iqr
    mask = (series < lower) | (series > upper)
    return mask, lower, upper


def remove_outliers(df: pd.DataFrame, processed_keys=None):
    """
    processed_keys: {(station, remark, file_path), ...}
    ì— í¬í•¨ëœ ì¡°í•©ì€ ì´ë²ˆ ì´ìƒì¹˜ ê³„ì‚° ëŒ€ìƒì—ì„œ ì œì™¸ (ì´ë¯¸ ì²˜ë¦¬ëœ ë°ì´í„°).
    """
    # 1) ctê°€ NULLì¸ í–‰ ì œê±°
    df_ct = df.dropna(subset=["ct"]).copy()

    # 2) file_path ê¸°ì¤€ ì¤‘ë³µ ì œê±°
    #    ê°™ì€ file_path, station, remark ì¡°í•©ì´ ì—¬ëŸ¬ ë²ˆ ìˆì„ ê²½ìš° â†’ ë§ˆì§€ë§‰ í–‰ë§Œ ì‚¬ìš©
    if "file_path" in df_ct.columns:
        df_ct = (
            df_ct
            .sort_values(["station", "remark", "end_day", "end_time"])
            .drop_duplicates(subset=["station", "remark", "file_path"], keep="last")
        )

    # === ì´ë¯¸ ì²˜ë¦¬ëœ ë°ì´í„° ì œê±° ===
    if processed_keys:
        key_series = list(zip(df_ct["station"], df_ct["remark"], df_ct["file_path"]))
        mask_new = [k not in processed_keys for k in key_series]
        df_ct = df_ct[mask_new]

    outlier_rows = []
    clean_rows = []

    for (station, remark), grp in df_ct.groupby(["station", "remark"]):
        mask, lower, upper = detect_outliers_iqr(grp["ct"])

        grp_out = grp[mask].copy()
        if not grp_out.empty:
            grp_out["Outliers"] = grp_out["ct"]
            outlier_rows.append(
                grp_out[[
                    "id", "station", "remark", "barcode_information", "ct",
                    "Outliers", "end_day", "end_time", "shift", "shift_date", "file_path"
                ]]
            )

        grp_clean = grp[~mask].copy()
        clean_rows.append(grp_clean)

    df_outliers = (
        pd.concat(outlier_rows, ignore_index=True)
        if outlier_rows
        else pd.DataFrame(columns=[
            "id", "station", "remark", "barcode_information", "ct",
            "Outliers", "end_day", "end_time", "shift", "shift_date", "file_path"
        ])
    )
    df_clean_new = (
        pd.concat(clean_rows, ignore_index=True)
        if clean_rows
        else pd.DataFrame(columns=[
            "id", "station", "remark", "barcode_information", "ct",
            "end_day", "end_time", "shift", "shift_date", "file_path"
        ])
    )

    print("\n[STEP 3] (ì‹ ê·œ ë°ì´í„°) ì´ìƒì¹˜ (ì• 10í–‰)")
    print(df_outliers.head(10).to_string(index=False))

    print("\n[STEP 4] (ì‹ ê·œ ë°ì´í„°) ì´ìƒì¹˜ ì œê±° í›„ ë°ì´í„° (ì• 10í–‰)")
    print(df_clean_new.head(10).to_string(index=False))

    return df_clean_new, df_outliers


# ===========================
# 4. Bootstrap (ë©€í‹°í”„ë¡œì„¸ì‹±)
# ===========================
def bootstrap_ci_mean(series: pd.Series,
                      n_boot: int = N_BOOTSTRAP,
                      ci: float = CI_LEVEL):
    series = series.dropna()
    if len(series) == 0:
        return np.nan, np.nan, np.nan

    means = []
    n = len(series)
    for _ in range(n_boot):
        sample = series.sample(n, replace=True)
        means.append(sample.mean())

    means = np.array(means)
    alpha = 100.0 - ci
    lower = np.percentile(means, alpha / 2.0)
    upper = np.percentile(means, 100.0 - alpha / 2.0)
    return float(series.mean()), float(lower), float(upper)


def _bootstrap_one_group(args):
    station, remark, values = args
    s = pd.Series(values)
    mean_ct, ci_low, ci_high = bootstrap_ci_mean(s)
    return {
        "station": station,
        "remark": remark,
        "ct": round(mean_ct, 2),
        "ci_low": round(ci_low, 2),
        "ci_high": round(ci_high, 2),
    }


def compute_bootstrap_ci(df_clean: pd.DataFrame) -> pd.DataFrame:
    tasks = []
    for (station, remark), grp in df_clean.groupby(["station", "remark"]):
        tasks.append((station, remark, grp["ct"].values))

    if not tasks:
        return pd.DataFrame(columns=["station", "remark", "ct", "ci_low", "ci_high"])

    with ProcessPoolExecutor(max_workers=N_BOOTSTRAP_WORKERS) as ex:
        results = list(ex.map(_bootstrap_one_group, tasks))

    df_ci = pd.DataFrame(results)

    print(f"\n[STEP 4-1] station/remarkë³„ CT í‰ê·  + Bootstrap {N_BOOTSTRAP}íšŒ, {CI_LEVEL}% CI")
    print(df_ci.to_string(index=False))

    return df_ci


def add_box_stats_annotations(fig: 'go.Figure',
                              df: pd.DataFrame,
                              x_col: str,
                              y_col: str,
                              label_prefix: str = ""):
    """
    df ê¸°ì¤€ìœ¼ë¡œ x_col ì¹´í…Œê³ ë¦¬ë³„ boxplot í†µê³„ (min, q1, median, q3, max)ë¥¼ ê³„ì‚°í•´ì„œ
    figì— annotationìœ¼ë¡œ í•­ìƒ í‘œì‹œí•´ ì¤€ë‹¤.
    label_prefix: 'Vision2 / PD' ê°™ì€ ì•ë¶€ë¶„ ë¬¸ìì—´ ë„£ì„ ë•Œ ì‚¬ìš© (ì„ íƒ)
    """
    if df.empty:
        return

    # describeë¡œ ê¸°ë³¸ í†µê³„ ê³„ì‚°
    stats = (
        df.groupby(x_col)[y_col]
          .describe(percentiles=[0.25, 0.5, 0.75])
          .reset_index()
    )
    stats = stats.rename(columns={
        "min": "min",
        "25%": "q1",
        "50%": "median",
        "75%": "q3",
        "max": "max",
    })

    for _, row in stats.iterrows():
        x_val = row[x_col]
        # í‘œì‹œí•  ì§€í‘œë“¤
        entries = [
            ("min", row["min"]),
            ("q1", row["q1"]),
            ("median", row["median"]),
            ("q3", row["q3"]),
            ("max", row["max"]),
        ]

        # ê¸€ìê°€ ê²¹ì¹˜ì§€ ì•Šê²Œ y ë°©í–¥ìœ¼ë¡œ ì‚´ì§ì”© ë°€ì–´ì¤Œ
        y_shift_step = 10
        for i, (name, y_val) in enumerate(entries):
            text = f"{label_prefix}{name}: {y_val:.2f}"
            fig.add_annotation(
                x=x_val,
                y=y_val,
                text=text,
                showarrow=False,
                xanchor="left",
                yanchor="bottom",
                font=dict(size=10),
                yshift=i * y_shift_step,
            )


# ===========================
# 5. Plotly ëŒ€ì‹œë³´ë“œ (í•œ HTMLì— 2ê°œ ê·¸ë˜í”„ ì¢Œìš°)
# ===========================
def save_dashboard_html(df_ci: pd.DataFrame, df_clean: pd.DataFrame, month_str: str) -> str:
    """
    ë¶€íŠ¸ìŠ¤íŠ¸ë© bar + ì¢…í•© Boxplotì„ í•œ HTMLì— ì¢Œìš°ë¡œ ë°°ì¹˜.
    """
    global FIRST_OPEN   # â† ë°˜ë“œì‹œ í•¨ìˆ˜ ë§¨ ìœ„ì—ì„œ ì„ ì–¸í•´ì•¼ ì˜¤ë¥˜ê°€ ì•ˆë‚¨!

    if df_clean.empty or df_ci.empty:
        print("[INFO] df_clean ë˜ëŠ” df_ciê°€ ë¹„ì–´ ìˆì–´ì„œ ëŒ€ì‹œë³´ë“œ ìƒì„± ìŠ¤í‚µ")
        return

    ensure_plot_dir()

    # ---------- (1) CI ë§‰ëŒ€ ê·¸ë˜í”„ + í…ìŠ¤íŠ¸ ë¼ë²¨ ----------
    df_ci_plot = df_ci.copy()
    df_ci_plot["err_plus"] = df_ci_plot["ci_high"] - df_ci_plot["ct"]
    df_ci_plot["err_minus"] = df_ci_plot["ct"] - df_ci_plot["ci_low"]

    df_ci_plot["label"] = df_ci_plot.apply(
        lambda r: f"ct={r['ct']:.2f} (+{r['err_plus']:.2f} / -{r['err_minus']:.2f})",
        axis=1
    )

    fig_bar = px.bar(
        df_ci_plot,
        x="station",
        y="ct",
        color="remark",
        barmode="group",
        error_y="err_plus",
        error_y_minus="err_minus",
        text="label",
        title=(
            f"[{month_str}] Vision1 / Vision2, PD/Non-PDë³„ CT í‰ê·  "
            f"(Bootstrap {N_BOOTSTRAP}íšŒ, {CI_LEVEL}% CI)"
        )
    )
    fig_bar.update_traces(textposition="outside", cliponaxis=False)

    # ---------- (2) Boxplot ----------
    df_box = df_clean.copy()
    df_box["station_remark"] = df_box["station"] + " / " + df_box["remark"]

    fig_combined = px.box(
        df_box,
        x="station_remark",
        y="ct",
        points="outliers",
        title=f"[{month_str}] Vision1 / Vision2 Ã— PD / Non-PD CT ë¶„í¬ (Boxplot)"
    )
    fig_combined.update_layout(xaxis_title="Station / Remark", yaxis_title="CT")

    add_box_stats_annotations(fig_combined, df_box, "station_remark", "ct")

    # ---------- (3) ë‘ ê·¸ë˜í”„ HTML ë³€í™˜ ----------
    figs = [fig_bar, fig_combined]
    fig_htmls = []
    for i, fig in enumerate(figs):
        html = pio.to_html(
            fig,
            include_plotlyjs="cdn" if i == 0 else False,
            full_html=False
        )
        fig_htmls.append(html)

    # â˜… 7ì´ˆ ìë™ ìƒˆë¡œê³ ì¹¨ ìŠ¤í¬ë¦½íŠ¸
    auto_refresh = """
    <script>
        setTimeout(function() {
            location.reload();
        }, 7000);
    </script>
    """

    # ---------- (4) ìµœì¢… HTML ----------
    full_html = f"""
<html>
<head>
<meta charset="utf-8">
{auto_refresh}
<style>
    body {{
        margin: 0;
        padding: 10px;
        font-family: Arial, sans-serif;
    }}
    .grid {{
        display: flex;
        flex-direction: row;
        width: 100vw;
        height: 100vh;
    }}
    .chart-half {{
        width: 50%;
        height: 100%;
        padding: 10px;
    }}
</style>
</head>
<body>
<div class="grid">
"""

    for html in fig_htmls:
        full_html += f'<div class="chart-half">{html}</div>'

    full_html += """
</div>
</body>
</html>
"""

    # ---------- (5) íŒŒì¼ ì €ì¥ ----------
    out_path = os.path.join(PLOT_DIR, PLOT_FILE)
    abs_path = os.path.abspath(out_path)
    with open(out_path, "w", encoding="utf-8") as f:
        f.write(full_html)

    print(f"[INFO] ê·¸ë˜í”„ HTML ìƒì„± ì™„ë£Œ: {abs_path}")
    print(f"[DEBUG] FIRST_OPEN = {FIRST_OPEN}")

    # ---------- (6) ìµœì´ˆ 1íšŒ ë¸Œë¼ìš°ì € ì˜¤í”ˆ ----------
    if FIRST_OPEN:
        try:
            FIRST_OPEN = False
            url = "file://" + abs_path
            print(f"[DEBUG] ë¸Œë¼ìš°ì € ì˜¤í”ˆ ì‹œë„: {url}")
            webbrowser.open_new_tab(url)
            print("[INFO] ë¸Œë¼ìš°ì € ì˜¤í”ˆ ì„±ê³µ")
        except Exception as e:
            print("[ERROR] webbrowser.open ì‹¤íŒ¨:", repr(e))
    else:
        print("[INFO] ê¸°ì¡´ ë¸Œë¼ìš°ì €ëŠ” ìë™ ìƒˆë¡œê³ ì¹¨ë§Œ ë™ì‘")

    return full_html


# ===========================
# 6. remarkë³„ ìµœì¢… CT (/2)
# ===========================
def compute_final_ct(df_clean: pd.DataFrame) -> pd.DataFrame:
    df_remark_mean = (
        df_clean
        .groupby("remark")["ct"]
        .mean()
        .reset_index()
    )
    df_remark_mean["ct"] = (df_remark_mean["ct"] / 2).round(2)

    df_final = df_remark_mean.copy()
    df_final.insert(0, "id", range(1, len(df_final) + 1))

    print("\n[STEP 5] remarkë³„ ìµœì¢… CT (/2) ê²°ê³¼")
    print(df_final.to_string(index=False))

    return df_final


# ===========================
# 7. Month ê³„ì‚° + upsert (ë™ì¼ ë°ì´í„°ë©´ pass)
# ===========================
def add_month_and_save(engine: create_engine,
                       df_clean: pd.DataFrame,
                       df_final: pd.DataFrame):
    global LAST_RESULT

    if df_clean.empty:
        print("\n[WARN] df_cleanì´ ë¹„ì–´ìˆì–´ Monthë¥¼ ê³„ì‚°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return None, False

    shift_dt = pd.to_datetime(df_clean["shift_date"])
    month_ym = shift_dt.max().strftime("%Y-%m")

    df_final_with_month = df_final.copy()
    df_final_with_month["Month"] = month_ym

    print("\n[STEP 6] Month ì ìš© ìµœì¢… ê²°ê³¼")
    print(df_final_with_month.to_string(index=False))

    # ë™ì¼ ë°ì´í„° ì—¬ë¶€ ì²´í¬
    current = {row["remark"]: float(row["ct"])
               for _, row in df_final_with_month.iterrows()}
    prev = LAST_RESULT.get(month_ym)

    if prev == current:
        print(f"\n[INFO] {month_ym} ê²°ê³¼ê°€ ì´ì „ê³¼ ë™ì¼ â†’ DB/ê·¸ë˜í”„ ìŠ¤í‚µ")
        return month_ym, False

    # ìºì‹œ ê°±ì‹ 
    LAST_RESULT[month_ym] = current

    df_to_save = df_final_with_month[["Month", "remark", "ct"]].rename(columns={
        "Month": "month"
    })

    with engine.begin() as conn:
        conn.execute(text("CREATE SCHEMA IF NOT EXISTS e1_whole_ct;"))
        conn.execute(text("""
            CREATE TABLE IF NOT EXISTS e1_whole_ct.whole_ct (
                month   varchar(7),
                remark  varchar(20),
                ct      numeric
            );
        """))
        conn.execute(text("""
            CREATE UNIQUE INDEX IF NOT EXISTS whole_ct_month_remark_idx
            ON e1_whole_ct.whole_ct (month, remark);
        """))

        upsert_sql = text("""
            INSERT INTO e1_whole_ct.whole_ct (month, remark, ct)
            VALUES (:month, :remark, :ct)
            ON CONFLICT (month, remark)
            DO UPDATE SET ct = EXCLUDED.ct;
        """)

        for _, row in df_to_save.iterrows():
            conn.execute(upsert_sql, {
                "month": row["month"],
                "remark": row["remark"],
                "ct": float(row["ct"]),
            })

    print("\n[STEP 7] e1_whole_ct.whole_ct í…Œì´ë¸” upsert ì™„ë£Œ")
    print(df_to_save.to_string(index=False))

    return month_ym, True


# ===========================
# í•œ ì‚¬ì´í´ ì‹¤í–‰ (â˜… ê¸°ì¡´ clean + ì‹ ê·œ clean í•©ì¹˜ê¸°)
# ===========================
def run_one_cycle(engine):
    print("\n==============================")
    print("[CYCLE START]", datetime.now())
    print("==============================")

    # 1) VIEWì—ì„œ RAW ë¡œë“œ
    df_raw = load_data(engine)
    if df_raw.empty:
        print("[INFO] RAW DATA ì—†ìŒ")
        return

    # 2) ì´ë¯¸ ì²˜ë¦¬ëœ clean ë°ì´í„° ë¡œë“œ
    df_old_clean = load_processed_clean(engine)
    print(f"[INFO] ì´ë¯¸ ì²˜ë¦¬ëœ clean ë°ì´í„° ìˆ˜: {len(df_old_clean)}")

    # 3) RAW ì „ì²´ì— shift ì •ë³´ ë¶€ì—¬
    df_shift = add_shift_info(df_raw)

    # 4) ì´ë¯¸ ì²˜ë¦¬ëœ (station, remark, file_path) ì¡°í•© ë§Œë“¤ê¸°
    if not df_old_clean.empty:
        processed_keys = set(
            zip(df_old_clean["station"], df_old_clean["remark"], df_old_clean["file_path"])
        )
    else:
        processed_keys = set()

    # 5) ì‹ ê·œ ë°ì´í„°ë§Œ IQR ì´ìƒì¹˜ ê³„ì‚°
    df_new_clean, df_outliers = remove_outliers(df_shift, processed_keys=processed_keys)
    print(f"[DEBUG] ì´ë²ˆ ì‚¬ì´í´ ì‹ ê·œ clean ë°ì´í„° ìˆ˜: {len(df_new_clean)}")

    if df_new_clean.empty and not df_old_clean.empty:
        print("[INFO] ì‹ ê·œ clean ë°ì´í„° ì—†ìŒ â†’ ì´ë²ˆ ì‚¬ì´í´ ê³„ì‚° ìŠ¤í‚µ (ê¸°ì¡´ ê²°ê³¼ ìœ ì§€)")
        return
    elif df_new_clean.empty and df_old_clean.empty:
        print("[INFO] ì²˜ë¦¬í•  clean ë°ì´í„°ê°€ ì „í˜€ ì—†ìŒ")
        return

    # 4) ì´ë¯¸ ì²˜ë¦¬ëœ (station, remark, file_path) ì¡°í•© ë§Œë“¤ê¸°
    if not df_old_clean.empty:
        processed_keys = set(
            zip(df_old_clean["station"], df_old_clean["remark"], df_old_clean["file_path"])
        )
    else:
        processed_keys = set()

    # 5) ì‹ ê·œ ë°ì´í„°ë§Œ IQR ì´ìƒì¹˜ ê³„ì‚°
    df_new_clean, df_outliers = remove_outliers(df_shift, processed_keys=processed_keys)

    if df_new_clean.empty and not df_old_clean.empty:
        print("[INFO] ì‹ ê·œ clean ë°ì´í„° ì—†ìŒ â†’ ì´ë²ˆ ì‚¬ì´í´ ê³„ì‚° ìŠ¤í‚µ (ê¸°ì¡´ ê²°ê³¼ ìœ ì§€)")
        return
    elif df_new_clean.empty and df_old_clean.empty:
        print("[INFO] ì²˜ë¦¬í•  clean ë°ì´í„°ê°€ ì „í˜€ ì—†ìŒ")
        return

    # 6) ê¸°ì¡´ + ì‹ ê·œ clean ë°ì´í„° í•©ì¹˜ê¸°
    if not df_old_clean.empty:
        df_clean = pd.concat([df_old_clean, df_new_clean], ignore_index=True)
    else:
        df_clean = df_new_clean

    print(f"[INFO] í•©ì³ì§„ clean ë°ì´í„° ìˆ˜: {len(df_clean)}")

    # 7) ë¶€íŠ¸ìŠ¤íŠ¸ë© CI, remarkë³„ ìµœì¢… CT ê³„ì‚°
    df_ci = compute_bootstrap_ci(df_clean)
    df_final = compute_final_ct(df_clean)
    month_ym, updated = add_month_and_save(engine, df_clean, df_final)

    # month ê³„ì‚° ì‹¤íŒ¨ or ë™ì¼ ë°ì´í„°ë©´ ê·¸ë˜í”„/DB ìŠ¤í‚µ
    if (month_ym is None) or (not updated):
        # ê·¸ë˜ë„ ì‹ ê·œ cleanì´ ìˆë‹¤ë©´ processing ì—ëŠ” ì €ì¥
        if not df_new_clean.empty:
            save_new_clean(engine, df_new_clean)
        return

    # 8) ë°ì´í„° ë³€ê²½ì´ ìˆì„ ë•Œë§Œ ëŒ€ì‹œë³´ë“œ HTML ì—…ë°ì´íŠ¸ + DB ì €ì¥
    html = save_dashboard_html(df_ci, df_clean, month_ym)
    save_ct_graph_html(engine, month_ym, df_final, html)

    # 9) ë§ˆì§€ë§‰ìœ¼ë¡œ ì‹ ê·œ clean ë°ì´í„°ë§Œ processing í…Œì´ë¸”ì— ì ì¬
    if not df_new_clean.empty:
        save_new_clean(engine, df_new_clean)


# ===========================
# ct_graph_html ì €ì¥
# ===========================
def save_ct_graph_html(engine: create_engine,
                       month_ym: str,
                       df_final: pd.DataFrame,
                       html: str):
    """
    e1_whole_ct.ct_graph_html ì— Plotly ëŒ€ì‹œë³´ë“œ HTML ì €ì¥.
    - í‚¤: (month, remark)
    - ê°™ì€ month+remarkì— ëŒ€í•´ì„œëŠ” htmlì„ ì—…ë°ì´íŠ¸ (ì¤‘ë³µ ì—†ìŒ)
    """
    if not html:
        print("\n[INFO] HTML ë‚´ìš©ì´ ë¹„ì–´ ìˆì–´ ct_graph_html ì €ì¥ ìŠ¤í‚µ")
        return

    if df_final.empty:
        print("\n[INFO] df_finalì´ ë¹„ì–´ ìˆì–´ ct_graph_html ì €ì¥ ìŠ¤í‚µ")
        return

    with engine.begin() as conn:
        conn.execute(text("CREATE SCHEMA IF NOT EXISTS e1_whole_ct;"))
        conn.execute(text("""
            CREATE TABLE IF NOT EXISTS e1_whole_ct.ct_graph_html (
                month   varchar(7),
                remark  varchar(20),
                html    text
            );
        """))
        conn.execute(text("""
            CREATE UNIQUE INDEX IF NOT EXISTS ct_graph_html_month_remark_idx
            ON e1_whole_ct.ct_graph_html (month, remark);
        """))

        upsert_sql = text("""
            INSERT INTO e1_whole_ct.ct_graph_html (month, remark, html)
            VALUES (:month, :remark, :html)
            ON CONFLICT (month, remark)
            DO UPDATE SET html = EXCLUDED.html;
        """)

        for _, row in df_final.iterrows():
            conn.execute(upsert_sql, {
                "month": month_ym,
                "remark": row["remark"],
                "html": html,
            })

    print(f"\n[STEP 8] e1_whole_ct.ct_graph_html ì €ì¥ ì™„ë£Œ (month={month_ym})")


# ===========================
# main: 1ì´ˆë§ˆë‹¤ ë¬´í•œ ë£¨í”„
# ===========================
def main_loop():
    engine = get_engine()
    while True:
        try:
            run_one_cycle(engine)
        except Exception as e:
            print("\n[ERROR] ì‚¬ì´í´ ì‹¤í–‰ ì¤‘ ì˜ˆì™¸ ë°œìƒ:", repr(e))
        time_mod.sleep(LOOP_INTERVAL_SEC)


if __name__ == "__main__":
    main_loop()