import re
import math
from pathlib import Path
from datetime import datetime, date
import time
from multiprocessing import Pool, cpu_count, freeze_support
import calendar

import psycopg2
from psycopg2 import sql


# =========================
# ê¸°ë³¸ ê²½ë¡œ ì„¤ì •
# =========================
BASE_LOG_DIR = Path(r"\\192.168.108.155\FCT LogFile\Machine Log\FCT")

# =========================
# PostgreSQL ì„¤ì •
# =========================
DB_CONFIG = {
    "host": "192.168.108.162",
    "port": 5432,
    "dbname": "postgres",
    "user": "postgres",
    "password": "leejangwoo1!",
}

SCHEMA_PROCESSING = "c1_fct_testlog_detail_jason_processing"
TABLE_PROCESSING = "fct_testlog_detail_jason_processing"

SCHEMA_RESULT = "c1_fct_testlog_detail_result"
TABLE_RESULT = "fct_testlog_detail_result"

# ê³ ì • ìµœì†Œ ì‹œì‘ì¼ (ì´ ë‚ ì§œ ì´ì „ ë°ì´í„°ëŠ” ë¬´ì‹œ)
FIXED_START_DATE = date(2025, 10, 1)

# í•œ ë²ˆì— INSERTí•  ìµœëŒ€ row ìˆ˜ (í–¥í›„ ë°°ì¹˜ í™•ì¥ìš©)
BATCH_SIZE_ROWS = 50000

# ì‹¤ì‹œê°„ìš©: ìµœê·¼ Nì´ˆ ì´ë‚´ ìˆ˜ì •ëœ íŒŒì¼ë§Œ ì²˜ë¦¬
REALTIME_LOOKBACK_SECONDS = 120  # ì˜ˆ: ìµœê·¼ 2ë¶„


# =========================
# ë‚ ì§œ ìœˆë„ìš° ìœ í‹¸
# =========================
def six_months_ago(d: date) -> date:
    """
    ì˜¤ëŠ˜ ê¸°ì¤€ 6ê°œì›” ì „ ë‚ ì§œ ê³„ì‚° (í˜„ì¬ëŠ” ì‚¬ìš©í•˜ì§€ ì•Šì§€ë§Œ ì°¸ê³ ìš©ìœ¼ë¡œ ë‚¨ê²¨ë‘ ).
    """
    year = d.year
    month = d.month - 6
    if month <= 0:
        year -= 1
        month += 12

    last_day = calendar.monthrange(year, month)[1]
    day = min(d.day, last_day)
    return date(year, month, day)


def get_window_dates():
    """
    ì˜¤ëŠ˜ ë‚ ì§œ ê¸°ì¤€ìœ¼ë¡œ 'ì´ë²ˆ ë‹¬ 1ì¼ ~ ì˜¤ëŠ˜' ë²”ìœ„ë¥¼ ë°˜í™˜.
    FIXED_START_DATE ì´ì „ì€ ë¬´ì¡°ê±´ ì œì™¸.
    """
    today = date.today()

    # ì´ë²ˆ ë‹¬ 1ì¼
    month_start = today.replace(day=1)

    # ê³ ì • ì‹œì‘ì¼ ì´í›„ë§Œ
    window_start_date = max(month_start, FIXED_START_DATE)
    window_end_date = today
    return window_start_date, window_end_date


# =========================
# ìœ í‹¸ í•¨ìˆ˜ë“¤
# =========================
def read_lines_with_encodings(file_path: Path):
    """
    ì—¬ëŸ¬ ì¸ì½”ë”©(cp949, utf-8, utf-8-sig)ì„ ì‹œë„í•´ì„œ
    ê¸€ìê°€ ê¹¨ì§€ì§€ ì•Šë„ë¡ ì•ˆì „í•˜ê²Œ ì½ê¸°.
    """
    for enc in ("cp949", "utf-8", "utf-8-sig"):
        try:
            with file_path.open("r", encoding=enc) as f:
                return f.readlines()
        except UnicodeDecodeError:
            continue

    # ê·¸ë˜ë„ ì•ˆ ë˜ë©´ ë§ˆì§€ë§‰ì—ë§Œ ignore ì‚¬ìš©
    with file_path.open("r", encoding="utf-8", errors="ignore") as f:
        return f.readlines()


def extract_yyyymmdd_from_name(name: str) -> str:
    """
    íŒŒì¼ëª…(stem)ì—ì„œ YYYYMMDD ì¶”ì¶œ.
    ìš°ì„  ì •ê·œì‹ìœ¼ë¡œ 20xxxxxx (8ìë¦¬ ìˆ«ì) íŒ¨í„´ì„ ì°¾ê³ ,
    ì—†ìœ¼ë©´ ì‚¬ìš©ìê°€ ë§í•œ ê·œì¹™:
      - ì²« ë²ˆì§¸ '-' ì™€ ê·¸ ë’¤ ì²« ë²ˆì§¸ '_' ì‚¬ì´
    ë¥¼ ì‹œë„í•œë‹¤.
    """
    # 1) ì •ê·œì‹ìœ¼ë¡œ 8ìë¦¬ ë‚ ì§œ(20xxxxxx) ì°¾ê¸°
    candidates = re.findall(r"(20\d{6})", name)
    if candidates:
        # ë§ˆì§€ë§‰ ìª½ì´ ì§„ì§œ ë‚ ì§œì¼ ê°€ëŠ¥ì„±ì´ í¼
        return candidates[-1]

    # 2) fallback: ì²« ë²ˆì§¸ '-' ì™€ ê·¸ ë’¤ ì²« ë²ˆì§¸ '_' ì‚¬ì´
    dash_pos = name.find("-")
    if dash_pos != -1:
        underscore_pos = name.find("_", dash_pos + 1)
        if underscore_pos != -1 and underscore_pos > dash_pos + 1:
            candidate = name[dash_pos + 1:underscore_pos]
            if candidate.isdigit() and len(candidate) == 8:
                return candidate

    # 3) ê·¸ë˜ë„ ëª» ì°¾ìœ¼ë©´ ë¹ˆ ë¬¸ìì—´
    return ""


def parse_filename(filepath: Path):
    """
    íŒŒì¼ëª…ì—ì„œ Barcode information, YYYYMMDD ì¶”ì¶œ

    ê·œì¹™(ë³µí•©):
    1) í™•ì¥ì(.txt) ì œê±°
    2) ì²« ë²ˆì§¸ '_' ì•ê¹Œì§€ â†’ Barcode information
    3) YYYYMMDD:
       - ìš°ì„  ì •ê·œì‹(20xxxxxx 8ìë¦¬)ìœ¼ë¡œ ì°¾ê¸°
       - ì—†ìœ¼ë©´ 'ì²« ë²ˆì§¸ - ì™€ ë‘ ë²ˆì§¸ _ ì‚¬ì´' ê·œì¹™ ì‹œë„
    """
    name = filepath.stem  # í™•ì¥ì ì œê±°

    # 2) Barcode information
    if "_" in name:
        barcode = name.split("_", 1)[0]
    else:
        barcode = name  # '_'ê°€ ì—†ìœ¼ë©´ ì „ì²´ë¥¼ ë°”ì½”ë“œë¡œ

    # 3) YYYYMMDD
    yyyymmdd = extract_yyyymmdd_from_name(name)

    return barcode, yyyymmdd


def parse_time_line(line: str):
    """
    ë¡œê·¸ í•œ ì¤„ì—ì„œ [hh:mm:ss.ss] ì™€ Test_item, Test_Time ì¶”ì¶œ
    - [hh:mm:ss.ss] ê°€ ì—†ìœ¼ë©´ (None, None, None) ë°˜í™˜
    - Test_item ë‚´ë¶€ì˜ 2ê°œ ì´ìƒ ê³µë°±ì€ 1ê°œë¡œ ì¶•ì†Œ
    - Test_Time ì€ time_str ê·¸ëŒ€ë¡œ (hh:mm:ss.ss)
    """
    m = re.search(r"\[(\d{2}:\d{2}:\d{2}\.\d{2})\]\s+(.*)", line)
    if not m:
        return None, None, None

    time_str = m.group(1)  # "hh:mm:ss.ss"
    test_item_raw = m.group(2)

    # ë‚´ìš©ì•ˆì— ê³µë°± 1ê°œê¹Œì§€ í—ˆìš©, 2ê°œ ì´ìƒì˜ ê³µë°±ì€ 1ê°œë¡œ ì¶•ì†Œ
    test_item = re.sub(r"\s{2,}", " ", test_item_raw).strip()

    test_time = time_str  # ê·¸ëŒ€ë¡œ ì €ì¥

    return time_str, test_item, test_time


def time_to_seconds(time_str: str) -> float:
    """
    "hh:mm:ss.ss" â†’ ì´ˆ(float)ë¡œ ë³€í™˜
    """
    t = datetime.strptime(time_str, "%H:%M:%S.%f")
    return t.hour * 3600 + t.minute * 60 + t.second + t.microsecond / 1_000_000


def get_end_time_str(last_time_str: str) -> str:
    """
    ë§ˆì§€ë§‰ [hh:mm:ss.ss] ì—ì„œ hh:mm:ss ë§Œ ì¶”ì¶œí•´ ë¬¸ìì—´ë¡œ ë°˜í™˜
    """
    t = datetime.strptime(last_time_str, "%H:%M:%S.%f")
    return t.strftime("%H:%M:%S")


def is_valid_deep_fct_path(p: Path, window_start_str: str, window_end_str: str) -> bool:
    """
    BASE_LOG_DIR ê¸°ì¤€ ìƒëŒ€ê²½ë¡œê°€
    YYYY/MM/DD/ì–´ë–¤í´ë”/íŒŒì¼ êµ¬ì¡°ì¸ì§€ í™•ì¸í•˜ê³ ,
    ê·¸ YYYYMMDDê°€ window_start_str ~ window_end_str ë²”ìœ„ì— ë“¤ì–´ê°€ëŠ”ì§€ í™•ì¸.
    """
    try:
        rel = p.relative_to(BASE_LOG_DIR)
    except ValueError:
        return False

    parts = rel.parts  # ('2025', '10', '01', '...', 'file.txt') ë“±

    # ìµœì†Œ êµ¬ì¡°: YYYY / MM / DD / (í´ë”) / íŒŒì¼ â†’ 4ê°œ ì´ìƒ
    if len(parts) < 4:
        return False

    year, month, day = parts[0], parts[1], parts[2]

    if not (year.isdigit() and len(year) == 4):
        return False
    if not (month.isdigit() and len(month) == 2):
        return False
    if not (day.isdigit() and len(day) == 2):
        return False

    yyyymmdd = f"{year}{month}{day}"

    # ë‚ ì§œ ìœˆë„ìš° ë²”ìœ„ ì²´í¬
    if not (window_start_str <= yyyymmdd <= window_end_str):
        return False

    return True


def extract_result_from_lines(lines):
    """
    íŒŒì¼ ì „ì²´ ë¼ì¸ì—ì„œ 'í…ŒìŠ¤íŠ¸ ê²°ê³¼ : NG/OK' ë¥¼ ì°¾ì•„ PASS/FAIL ë¦¬í„´.
    - ë§ˆì§€ë§‰ì— ë‚˜ì˜¤ëŠ” ê²°ê³¼ ê¸°ì¤€.
    - NG â†’ 'FAIL', OK â†’ 'PASS'
    - ëª» ì°¾ìœ¼ë©´ None
    """
    for line in reversed(lines):
        m = re.search(
            r"\[\d{2}:\d{2}:\d{2}\.\d{2}\]\s*í…ŒìŠ¤íŠ¸ ê²°ê³¼\s*:\s*(NG|OK)",
            line,
        )
        if m:
            status = m.group(1).strip().upper()
            if status == "NG":
                return "FAIL"
            elif status == "OK":
                return "PASS"
    return None


def process_one_file(file_path_str: str):
    """
    ë©€í‹°í”„ë¡œì„¸ìŠ¤ì—ì„œ ì‚¬ìš©í•  ì›Œì»¤ í•¨ìˆ˜.
    í•˜ë‚˜ì˜ txt íŒŒì¼ì„ íŒŒì‹±í•´ì„œ (file_path, rows, error) ë°˜í™˜.

    rows ì˜ ê° ì›ì†ŒëŠ” ì•„ë˜ ì»¬ëŸ¼ì„ ê°€ì§:
    - file_path
    - yyyymmdd
    - end_time
    - barcode_information
    - test_item
    - test_time
    - test_item_ct
    - result   â† PASS/FAIL (ì—†ìœ¼ë©´ None)
    """
    file_path = Path(file_path_str)
    try:
        barcode, yyyymmdd = parse_filename(file_path)

        # íŒŒì¼ ë‚´ìš© ì½ê¸° (ì¸ì½”ë”© ìë™ ì²˜ë¦¬)
        lines = read_lines_with_encodings(file_path)

        # íŒŒì¼ ì „ì²´ì—ì„œ í…ŒìŠ¤íŠ¸ ê²°ê³¼(PASS/FAIL) ì¶”ì¶œ
        result_status = extract_result_from_lines(lines)

        events = []  # (time_str, test_item, test_time)

        for line in lines:
            time_str, test_item, test_time = parse_time_line(line)
            if time_str is None:
                # [hh:mm:ss.ss] ê°€ ì—†ëŠ” í–‰ì€ ì™„ì „íˆ ë¬´ì‹œ
                continue
            events.append((time_str, test_item, test_time))

        # ìœ íš¨í•œ íƒ€ì„ìŠ¤íƒ¬í”„ê°€ í•˜ë‚˜ë„ ì—†ìœ¼ë©´ ì´ íŒŒì¼ì€ ìŠ¤í‚µ
        if not events:
            return file_path_str, [], None

        # End time: ë§ˆì§€ë§‰ ì´ë²¤íŠ¸ì˜ ì‹œê°„ì—ì„œ hh:mm:ss ì¶”ì¶œ
        last_time_str = events[-1][0]
        end_time = get_end_time_str(last_time_str)

        # Test_item_CT ê³„ì‚°
        rows = []
        prev_sec = None

        for time_str, test_item, test_time in events:
            cur_sec = time_to_seconds(time_str)

            if prev_sec is None:
                ct_value = None  # ì²« ë²ˆì§¸ Test_itemì€ NULL
            else:
                diff = cur_sec - prev_sec
                # ë§Œì•½ ì‹œê°„ ì°¨ê°€ ìŒìˆ˜ë©´(ìì • ë„˜ì–´ê°„ ê²½ìš° ë“±) 24ì‹œê°„ ë”í•´ì¤Œ
                if diff < 0:
                    diff += 24 * 3600
                ct_value = round(diff, 2)

            prev_sec = cur_sec

            rows.append(
                {
                    "file_path": file_path_str,
                    "yyyymmdd": yyyymmdd,
                    "end_time": end_time,
                    "barcode_information": barcode,
                    "test_item": test_item,
                    "test_time": test_time,
                    "test_item_ct": ct_value,
                    "result": result_status,
                }
            )

        return file_path_str, rows, None

    except Exception as e:
        return file_path_str, [], str(e)


# =========================
# PostgreSQL ê´€ë ¨ í•¨ìˆ˜
# =========================
def get_connection():
    return psycopg2.connect(**DB_CONFIG)


def ensure_schema_and_tables(conn):
    with conn.cursor() as cur:
        # ìŠ¤í‚¤ë§ˆ ìƒì„±
        cur.execute(sql.SQL("CREATE SCHEMA IF NOT EXISTS {}").format(sql.Identifier(SCHEMA_PROCESSING)))
        cur.execute(sql.SQL("CREATE SCHEMA IF NOT EXISTS {}").format(sql.Identifier(SCHEMA_RESULT)))

        # ì²˜ë¦¬ ì´ë ¥ í…Œì´ë¸”
        cur.execute(
            sql.SQL(
                """
                CREATE TABLE IF NOT EXISTS {}.{} (
                    id BIGSERIAL PRIMARY KEY,
                    file_path TEXT UNIQUE,
                    processed_time TIMESTAMP WITHOUT TIME ZONE DEFAULT NOW()
                )
                """
            ).format(sql.Identifier(SCHEMA_PROCESSING), sql.Identifier(TABLE_PROCESSING))
        )

        # ê²°ê³¼ ì €ì¥ í…Œì´ë¸” (result ì»¬ëŸ¼ í¬í•¨)
        cur.execute(
            sql.SQL(
                """
                CREATE TABLE IF NOT EXISTS {}.{} (
                    id BIGSERIAL PRIMARY KEY,
                    file_path TEXT NOT NULL,
                    yyyymmdd VARCHAR(8),
                    end_time VARCHAR(8),
                    barcode_information TEXT,
                    test_item TEXT,
                    test_time VARCHAR(12),
                    test_item_ct DOUBLE PRECISION,
                    result VARCHAR(10),
                    processed_time TIMESTAMP WITHOUT TIME ZONE DEFAULT NOW()
                )
                """
            ).format(sql.Identifier(SCHEMA_RESULT), sql.Identifier(TABLE_RESULT))
        )

        # ì´ë¯¸ ì¡´ì¬í•˜ëŠ” ê²½ìš°ë¥¼ ëŒ€ë¹„í•´ result ì»¬ëŸ¼ ë³´ì¥
        cur.execute(
            sql.SQL(
                "ALTER TABLE {}.{} "
                "ADD COLUMN IF NOT EXISTS result VARCHAR(10)"
            ).format(sql.Identifier(SCHEMA_RESULT), sql.Identifier(TABLE_RESULT))
        )

        # ğŸ”¹ ì¤‘ë³µ ë°©ì§€ìš© ìœ ë‹ˆí¬ ì¸ë±ìŠ¤
        #    (yyyymmdd, end_time, barcode_information, test_item) ì¡°í•©ì´ ìœ ì¼í•˜ë„ë¡
        cur.execute(
            sql.SQL(
                """
                CREATE UNIQUE INDEX IF NOT EXISTS idx_fct_testlog_detail_result_uniq4
                ON {}.{} (yyyymmdd, end_time, barcode_information, test_item)
                """
            ).format(sql.Identifier(SCHEMA_RESULT), sql.Identifier(TABLE_RESULT))
        )

    conn.commit()


def cleanup_old_data(conn, window_start_date: date):
    """
    ê¸°ì¤€ ë‚ ì§œ ì´ì „ ë°ì´í„° ì‚­ì œ.

    - ê²°ê³¼ í…Œì´ë¸” : yyyymmdd < window_start_str ì¸ ë°ì´í„° ì‚­ì œ
    - ì²˜ë¦¬ ì´ë ¥   : processed_time < window_start_date 00:00:00 ì¸ ë°ì´í„° ì‚­ì œ

    â€» í˜„ì¬ run_once()ì—ì„œëŠ” ìë™ í˜¸ì¶œí•˜ì§€ ì•ŠìŒ.
       í•„ìš” ì‹œ ìˆ˜ë™ìœ¼ë¡œ ëŒë¦¬ëŠ” ê²ƒì„ ê¶Œì¥.
    """
    window_start_str = window_start_date.strftime("%Y%m%d")
    cutoff_dt = datetime.combine(window_start_date, datetime.min.time())

    with conn.cursor() as cur:
        # ê²°ê³¼ í…Œì´ë¸” ì‚­ì œ (yyyymmdd ê¸°ì¤€)
        cur.execute(
            sql.SQL(
                """
                DELETE FROM {}.{}
                WHERE yyyymmdd IS NOT NULL
                  AND yyyymmdd <> ''
                  AND yyyymmdd < %s
                """
            ).format(sql.Identifier(SCHEMA_RESULT), sql.Identifier(TABLE_RESULT)),
            (window_start_str,),
        )
        deleted_result = cur.rowcount

        # ì²˜ë¦¬ ì´ë ¥ í…Œì´ë¸” ì‚­ì œ (processed_time ê¸°ì¤€)
        cur.execute(
            sql.SQL(
                """
                DELETE FROM {}.{}
                WHERE processed_time < %s
                """
            ).format(sql.Identifier(SCHEMA_PROCESSING), sql.Identifier(TABLE_PROCESSING)),
            (cutoff_dt,),
        )
        deleted_hist = cur.rowcount

    conn.commit()
    print(
        f"[ì •ë¦¬] ê¸°ì¤€ ì´ì „ ë°ì´í„° ì‚­ì œ ì™„ë£Œ "
        f"(result rows={deleted_result}, history rows={deleted_hist})"
    )


def get_processed_file_paths(conn, window_start_date: date):
    """
    ì´ë¯¸ ì²˜ë¦¬ëœ file_path ëª©ë¡ì„ DBì—ì„œ ê°€ì ¸ì™€ setìœ¼ë¡œ ë°˜í™˜.
    - processed_time >= window_start_date ê¸°ì¤€ìœ¼ë¡œë§Œ ì¡°íšŒ
      (ì´ë²ˆ ë‹¬ ìœˆë„ìš° ë‚´ ë°ì´í„°ë§Œ ì¤‘ë³µ ì²´í¬)
    """
    cutoff_dt = datetime.combine(window_start_date, datetime.min.time())

    with conn.cursor() as cur:
        cur.execute(
            sql.SQL(
                "SELECT file_path FROM {}.{} WHERE processed_time >= %s"
            ).format(
                sql.Identifier(SCHEMA_PROCESSING),
                sql.Identifier(TABLE_PROCESSING),
            ),
            (cutoff_dt,),
        )
        rows = cur.fetchall()
    return {r[0] for r in rows}


def insert_results_and_history(conn, file_path, rows):
    """
    í•œ íŒŒì¼ì— ëŒ€í•œ íŒŒì‹± ê²°ê³¼(rows)ë¥¼ ê²°ê³¼ í…Œì´ë¸”ì— INSERT í•˜ê³ ,
    ì²˜ë¦¬ ì´ë ¥ í…Œì´ë¸”ì—ë„ file_pathë¥¼ ê¸°ë¡.

    ğŸ”¹ (yyyymmdd, end_time, barcode_information, test_item) ì¡°í•©ì´
       ì´ë¯¸ ì¡´ì¬í•˜ë©´ í•´ë‹¹ í–‰ì€ INSERT í•˜ì§€ ì•ŠìŒ.
    """
    if not rows:
        return

    with conn.cursor() as cur:
        # ê²°ê³¼ í…Œì´ë¸”ì— ë‹¤ì¤‘ INSERT (result í¬í•¨)
        insert_query = sql.SQL(
            """
            INSERT INTO {}.{} (
                file_path,
                yyyymmdd,
                end_time,
                barcode_information,
                test_item,
                test_time,
                test_item_ct,
                result
            )
            VALUES (%(file_path)s, %(yyyymmdd)s, %(end_time)s,
                    %(barcode_information)s, %(test_item)s,
                    %(test_time)s, %(test_item_ct)s, %(result)s)
            ON CONFLICT (yyyymmdd, end_time, barcode_information, test_item) DO NOTHING
            """
        ).format(sql.Identifier(SCHEMA_RESULT), sql.Identifier(TABLE_RESULT))

        cur.executemany(insert_query, rows)

        # ì²˜ë¦¬ ì´ë ¥ í…Œì´ë¸”ì— file_path ê¸°ë¡ (ì¤‘ë³µì´ë©´ ë¬´ì‹œ)
        cur.execute(
            sql.SQL(
                """
                INSERT INTO {}.{} (file_path, processed_time)
                VALUES (%s, NOW())
                ON CONFLICT (file_path) DO NOTHING
                """
            ).format(sql.Identifier(SCHEMA_PROCESSING), sql.Identifier(TABLE_PROCESSING)),
            (file_path,),
        )

    conn.commit()


# =========================
# ë©”ì¸ 1íšŒ ìˆ˜í–‰ ë¡œì§
# =========================
def run_once():
    # ë‚ ì§œ ìœˆë„ìš° ê³„ì‚° (ì´ë²ˆ ë‹¬ 1ì¼ ~ ì˜¤ëŠ˜)
    window_start_date, window_end_date = get_window_dates()
    window_start_str = window_start_date.strftime("%Y%m%d")
    window_end_str = window_end_date.strftime("%Y%m%d")

    now_ts = time.time()
    cutoff_ts = now_ts - REALTIME_LOOKBACK_SECONDS

    print("\n================ run_once ì‹œì‘ ================")
    print(f"[ìœˆë„ìš°] ìœ íš¨ ë‚ ì§œ ë²”ìœ„: {window_start_date} ~ {window_end_date}")
    print(f"[ì‹¤ì‹œê°„] ìµœê·¼ {REALTIME_LOOKBACK_SECONDS}ì´ˆ ì´ë‚´ ìˆ˜ì •ëœ íŒŒì¼ë§Œ ì²˜ë¦¬ (cutoff_ts={cutoff_ts})")
    print(f"[DEBUG] BASE_LOG_DIR: {BASE_LOG_DIR}")

    # 0) DB ì—°ê²° ë° ìŠ¤í‚¤ë§ˆ/í…Œì´ë¸” ì¤€ë¹„
    conn = get_connection()
    ensure_schema_and_tables(conn)

    # 1) ì „ì²´ TXT íŒŒì¼ ìŠ¤ìº” (ìœˆë„ìš° + mtime í•„í„°)
    all_found_txt_files = list(BASE_LOG_DIR.rglob("*.txt"))

    all_txt_files = []
    for p in all_found_txt_files:
        if not is_valid_deep_fct_path(p, window_start_str, window_end_str):
            continue
        try:
            if p.stat().st_mtime < cutoff_ts:
                # ì‹¤ì‹œê°„ ìœˆë„ìš° ë°–ì´ë©´ ì œì™¸
                continue
        except FileNotFoundError:
            continue
        all_txt_files.append(p)

    print(f"1) TXT íŒŒì¼ ìŠ¤ìº” ì™„ë£Œ â†’ ì´ íŒŒì¼ ìˆ˜ì§‘(ìœˆë„ìš°+mtime ë‚´): {len(all_txt_files)}ê°œ")

    # 2) DB ì´ë ¥ ë¡œë“œ (ìœˆë„ìš° ë‚´ already processed)
    processed_file_paths = get_processed_file_paths(conn, window_start_date)
    print(f"2) DBì—ì„œ ë¶ˆëŸ¬ì˜¨ ì´ì „ ì²˜ë¦¬ íŒŒì¼ ìˆ˜(ìœˆë„ìš° ë‚´): {len(processed_file_paths)}ê°œ")

    target_files = [p for p in all_txt_files if str(p) not in processed_file_paths]
    total = len(target_files)
    print(f"3) ì´ë²ˆì— ìƒˆë¡œ ì²˜ë¦¬í•  ëŒ€ìƒ íŒŒì¼ ìˆ˜: {total}ê°œ")

    if total == 0:
        conn.close()
        print("   â†’ ìƒˆë¡œ ì²˜ë¦¬í•  íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        print("=============== run_once ì¢…ë£Œ ===============\n")
        return

    print("4) TXT íŒŒì¼ ë©€í‹°í”„ë¡œì„¸ìŠ¤ ì²˜ë¦¬ ì‹œì‘...")

    # ë©€í‹°í”„ë¡œì„¸ìŠ¤ í’€ êµ¬ì„± - í•­ìƒ 2ê°œ í”„ë¡œì„¸ìŠ¤ë§Œ ì‚¬ìš©
    num_workers = 2
    print(f"   â†’ ë©€í‹°í”„ë¡œì„¸ì‹± ì›Œì»¤ ìˆ˜: {num_workers}ê°œ")

    start_ts = time.time()

    with Pool(processes=num_workers) as pool:
        for idx, (file_path_str, rows, err) in enumerate(
            pool.imap_unordered(process_one_file, [str(p) for p in target_files]), start=1
        ):
            if err:
                print(f"   [ERROR] {file_path_str} ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {err}")
                continue

            if not rows:
                # ìœ íš¨ ë¡œê·¸ ì—†ìœ¼ë©´ skip
                continue

            # DBì— INSERT + ì´ë ¥ ê¸°ë¡ (íŒŒì¼ ë‹¨ìœ„, ë©”ëª¨ë¦¬ ìµœì†Œí™”)
            insert_results_and_history(conn, file_path_str, rows)

            # ì§„í–‰ ìƒí™© ì¶œë ¥
            if (idx % 1000 == 0) or (idx == total):
                print(f"   â†’ í˜„ì¬ {idx}/{total} íŒŒì¼ ì²˜ë¦¬ ë° DB ì €ì¥ ì™„ë£Œ")

    elapsed = time.time() - start_ts
    print(f"   â†’ ì´ë²ˆ run_once ì²˜ë¦¬ ì‹œê°„: {elapsed:.1f}ì´ˆ")
    print("=============== run_once ì¢…ë£Œ ===============\n")


# =========================
# ì—”íŠ¸ë¦¬ í¬ì¸íŠ¸
# =========================
def main():
    freeze_support()
    while True:
        try:
            run_once()
        except Exception as e:
            print(f"[MAIN ERROR] run_once ìˆ˜í–‰ ì¤‘ ì˜¤ë¥˜: {e}")
        # 1ì´ˆ ëŒ€ê¸° í›„ ë‹¤ì‹œ ì‹¤í–‰ (ë¬´í•œ ë£¨í”„)
        time.sleep(1)


if __name__ == "__main__":
    main()
