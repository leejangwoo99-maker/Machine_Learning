from pathlib import Path
from datetime import datetime, date
import time
import multiprocessing as mp
import calendar

import psycopg2
from psycopg2.extras import execute_batch

# ============================================
# 0. ê¸°ë³¸ ì„¤ì •
# ============================================
# ë¡œê·¸ ìœ„ì¹˜ (NAS HistoryLog)
BASE_LOG_DIR = Path(r"\\192.168.108.101\HistoryLog")
# BASE_LOG_DIR = Path(r"C:\Users\user\Desktop\RAW_LOG")  # ë¡œì»¬ í…ŒìŠ¤íŠ¸ìš©

# ì¤‘ê°„ í´ë” & íƒ€ê²Ÿ í´ë”
MIDDLE_FOLDERS = ["TC6", "TC7", "TC8", "TC9", "Vision03"]
TARGET_FOLDERS = ["GoodFile", "BadFile"]

# TC6~9 â†’ FCT1~4 ë§¤í•‘
FCT_MAP = {
    "TC6": "FCT1",
    "TC7": "FCT2",
    "TC8": "FCT3",
    "TC9": "FCT4",
}

# PostgreSQL ì ‘ì† ì •ë³´
DB_CONFIG = {
    "host": "192.168.108.162",
    "port": 5432,
    "dbname": "postgres",
    "user": "postgres",
    "password": "leejangwoo1!",
}

# ìŠ¤í‚¤ë§ˆ ì´ë¦„
SCHEMA_HISTORY = "a1_fct_vision_testlog_txt_processing_history"
SCHEMA_RESULT = "a1_fct_vision_testlog_txt_processing_result"
SCHEMA_DETAIL = "a1_fct_vision_testlog_txt_processing_result_detail"

# ê³ ì • ìµœì†Œ ì‹œì‘ì¼ (ì˜ˆ: 2025-10-01ë¶€í„°ë§Œ ë³¸ë‹¤)
FIXED_START_DATE = date(2025, 10, 1)

# í•œ ë²ˆì— ë©€í‹°í”„ë¡œì„¸ìŠ¤ë¡œ ì²˜ë¦¬í•  ìµœëŒ€ íŒŒì¼ ê°œìˆ˜ (ë©”ëª¨ë¦¬ ì ˆì•½ìš©)
BATCH_SIZE = 10000


# ============================================
# ë‚ ì§œ ìœ í‹¸: ì˜¤ëŠ˜ ê¸°ì¤€ 6ê°œì›” ì „ ê³„ì‚°
# ============================================
def one_month_ago(d: date) -> date:
    year = d.year
    month = d.month - 1
    if month <= 0:
        year -= 1
        month += 12

    last_day = calendar.monthrange(year, month)[1]
    day = min(d.day, last_day)
    return date(year, month, day)

def get_window_dates():
    """
    ì˜¤ëŠ˜ ë‚ ì§œ ê¸°ì¤€ìœ¼ë¡œ 'ì´ë²ˆ ë‹¬ 1ì¼ ~ ì˜¤ëŠ˜' ë²”ìœ„ë¥¼ ë°˜í™˜.
    ì˜ˆ)
      - ì˜¤ëŠ˜ = 2025-12-04 â†’ 2025-12-01 ~ 2025-12-04
      - ì˜¤ëŠ˜ = 2025-12-31 â†’ 2025-12-01 ~ 2025-12-31
      - ì˜¤ëŠ˜ = 2026-01-01 â†’ 2026-01-01 ~ 2026-01-01
    """
    today = date.today()

    # ì´ë²ˆ ë‹¬ 1ì¼
    # ì´ë²ˆ ë‹¬ 1ì¼
    month_start = today.replace(day=1)

    # FIXED_START_DATE ì´í›„ë¶€í„°ë§Œ ë³´ê² ë‹¤ëŠ” ì •ì±… ìœ ì§€
    window_start_date = max(month_start, FIXED_START_DATE)

    # ìœˆë„ìš° ëì€ 'ì˜¤ëŠ˜'
    window_end_date = today

    return window_start_date, window_end_date

# ============================================
# 1. DB ìœ í‹¸
# ============================================
def table_name_from_schema(schema: str) -> str:
    """
    ìŠ¤í‚¤ë§ˆëª…ì—ì„œ 'a1_'ë§Œ ì œê±°í•˜ì—¬ í…Œì´ë¸”ëª… ìƒì„±
    ì˜ˆ) a1_fct_vision_testlog_txt_processing_history
        -> fct_vision_testlog_txt_processing_history
    """
    return schema[3:] if schema.startswith("a1_") else schema


def get_connection():
    return psycopg2.connect(**DB_CONFIG)


def init_db(conn):
    """
    ìŠ¤í‚¤ë§ˆ / í…Œì´ë¸” ìë™ ìƒì„±
    """
    cur = conn.cursor()

    # ---------- history ----------
    sch = SCHEMA_HISTORY
    tbl = table_name_from_schema(sch)
    cur.execute(f"CREATE SCHEMA IF NOT EXISTS {sch};")
    cur.execute(
        f"""
        CREATE TABLE IF NOT EXISTS {sch}.{tbl} (
            id           BIGSERIAL PRIMARY KEY,
            full_path    TEXT NOT NULL,
            equipment    TEXT,
            date_folder  TEXT,
            good_bad     TEXT,
            filename     TEXT NOT NULL,
            processed_at TIMESTAMPTZ NOT NULL
        );
        """
    )
    cur.execute(
        f"CREATE INDEX IF NOT EXISTS idx_{tbl}_full_path ON {sch}.{tbl}(full_path);"
    )

    # ğŸ”¥ ì—¬ê¸° ì¶”ê°€
    cur.execute(
        f"CREATE UNIQUE INDEX IF NOT EXISTS uq_{tbl}_full_path ON {sch}.{tbl}(full_path);"
    )

    # ---------- result ----------
    sch = SCHEMA_RESULT
    tbl = table_name_from_schema(sch)
    cur.execute(f"CREATE SCHEMA IF NOT EXISTS {sch};")
    cur.execute(
        f"""
        CREATE TABLE IF NOT EXISTS {sch}.{tbl} (
            id              BIGSERIAL PRIMARY KEY,
            run_started_at  TIMESTAMPTZ NOT NULL,
            run_finished_at TIMESTAMPTZ NOT NULL,
            equipment       TEXT NOT NULL,
            file_count      INTEGER NOT NULL
        );
        """
    )

    # ---------- detail ----------
    sch = SCHEMA_DETAIL
    tbl = table_name_from_schema(sch)
    cur.execute(f"CREATE SCHEMA IF NOT EXISTS {sch};")
    cur.execute(
        f"""
        CREATE TABLE IF NOT EXISTS {sch}.{tbl} (
            id              BIGSERIAL PRIMARY KEY,
            run_started_at  TIMESTAMPTZ NOT NULL,
            run_finished_at TIMESTAMPTZ NOT NULL,
            path_label      TEXT NOT NULL,
            filename        TEXT NOT NULL,
            reason          TEXT NOT NULL
        );
        """
    )

    conn.commit()
    cur.close()


def cleanup_old_data(conn, window_start_date: date):
    """
    RDBMSì—ì„œ 'í˜„ì¬ ë‚ ì§œ ê¸°ì¤€ 6ê°œì›” ì´ìƒ ëœ ë°ì´í„°' ì™„ì „ ì‚­ì œ (DELETE ì‚¬ìš©).

    - history : date_folder < window_start_date (yyyymmdd ë¹„êµ)
    - result  : run_started_at < window_start_date 00:00:00
    - detail  : run_started_at < window_start_date 00:00:00
    """
    cutoff_str = window_start_date.strftime("%Y%m%d")
    cutoff_dt = datetime.combine(window_start_date, datetime.min.time())

    cur = conn.cursor()

    # history
    sch = SCHEMA_HISTORY
    tbl = table_name_from_schema(sch)
    cur.execute(
        f"""
        DELETE FROM {sch}.{tbl}
        WHERE date_folder < %s
        """,
        (cutoff_str,),
    )
    deleted_hist = cur.rowcount

    # result
    sch = SCHEMA_RESULT
    tbl = table_name_from_schema(sch)
    cur.execute(
        f"""
        DELETE FROM {sch}.{tbl}
        WHERE run_started_at < %s
        """,
        (cutoff_dt,),
    )
    deleted_res = cur.rowcount

    # detail
    sch = SCHEMA_DETAIL
    tbl = table_name_from_schema(sch)
    cur.execute(
        f"""
        DELETE FROM {sch}.{tbl}
        WHERE run_started_at < %s
        """,
        (cutoff_dt,),
    )
    deleted_det = cur.rowcount

    conn.commit()
    cur.close()

    print(
        f"[ì •ë¦¬] 6ê°œì›” ì´ì „ ë°ì´í„° ì‚­ì œ ì™„ë£Œ "
        f"(history={deleted_hist}, result={deleted_res}, detail={deleted_det})"
    )


def load_processed_paths(conn, window_start_date: date, window_end_date: date):
    """
    ì´ë¯¸ PostgreSQL history í…Œì´ë¸”ì— ì˜¬ë¼ê°„ full_pathë¥¼ ì½ì–´ì„œ setìœ¼ë¡œ ë°˜í™˜.
    >> date_folderë¥¼ window_start_date ~ window_end_date ë²”ìœ„ë¡œ ì œí•œí•´ì„œ ë©”ëª¨ë¦¬ ì ˆì•½.
    """
    sch = SCHEMA_HISTORY
    tbl = table_name_from_schema(sch)
    cur = conn.cursor()

    start_str = window_start_date.strftime("%Y%m%d")
    end_str = window_end_date.strftime("%Y%m%d")

    cur.execute(
        f"""
        SELECT full_path
        FROM {sch}.{tbl}
        WHERE date_folder BETWEEN %s AND %s
        """,
        (start_str, end_str),
    )
    rows = cur.fetchall()
    cur.close()

    processed_full_paths = {fp for (fp,) in rows if fp}
    return processed_full_paths


def insert_history_rows(conn, rows):
    if not rows:
        return 0
    sch = SCHEMA_HISTORY
    tbl = table_name_from_schema(sch)
    cur = conn.cursor()
    execute_batch(
        cur,
        f"""
        INSERT INTO {sch}.{tbl}
            (full_path, equipment, date_folder, good_bad, filename, processed_at)
        VALUES (%s, %s, %s, %s, %s, %s)
        ON CONFLICT (full_path) DO NOTHING
        """,
        [
            (
                r["full_path"],
                r["equipment"],
                r["date_folder"],
                r["good_bad"],
                r["filename"],
                r["processed_at"],
            )
            for r in rows
        ],
        page_size=1000,
    )
    conn.commit()
    inserted = cur.rowcount  # ì‹¤ì œ ë“¤ì–´ê°„ í–‰ ìˆ˜
    cur.close()
    return inserted

def insert_result_rows(conn, rows):
    if not rows:
        return 0
    sch = SCHEMA_RESULT
    tbl = table_name_from_schema(sch)
    cur = conn.cursor()
    execute_batch(
        cur,
        f"""
        INSERT INTO {sch}.{tbl}
            (run_started_at, run_finished_at, equipment, file_count)
        VALUES (%s, %s, %s, %s)
        """,
        [
            (
                r["run_started_at"],
                r["run_finished_at"],
                r["equipment"],
                r["file_count"],
            )
            for r in rows
        ],
        page_size=100,
    )
    conn.commit()
    cur.close()
    return len(rows)


def insert_detail_rows(conn, rows):
    if not rows:
        return 0
    sch = SCHEMA_DETAIL
    tbl = table_name_from_schema(sch)
    cur = conn.cursor()
    execute_batch(
        cur,
        f"""
        INSERT INTO {sch}.{tbl}
            (run_started_at, run_finished_at, path_label, filename, reason)
        VALUES (%s, %s, %s, %s, %s)
        """,
        [
            (
                r["run_started_at"],
                r["run_finished_at"],
                r["path_label"],
                r["filename"],
                r["reason"],
            )
            for r in rows
        ],
        page_size=1000,
    )
    conn.commit()
    cur.close()
    return len(rows)


# ============================================
# 2. Vision03 ì„¤ë¹„ ë¶„ë¥˜
# ============================================
def classify_vision_equipment(file_path: Path):
    """
    íŒŒì¼ 6ë²ˆì§¸ ì¤„ì˜ Test Programìœ¼ë¡œ Vision1/Vision2 ê²°ì •
    >> ë©”ëª¨ë¦¬ ì ˆì•½: 6ì¤„ê¹Œì§€ë§Œ ìˆœì°¨ ì½ê¸°
    """
    equipment = "Vision?"
    test_program = None
    try:
        with open(file_path, "r", encoding="cp949", errors="ignore") as f:
            for i, line in enumerate(f, start=1):
                if i == 6:  # 6ë²ˆì§¸ ì¤„
                    if "Test Program" in line:
                        if "LED1" in line:
                            equipment, test_program = "Vision1", "LED1"
                        elif "LED2" in line:
                            equipment, test_program = "Vision2", "LED2"
                        else:
                            equipment = "Vision3"
                    else:
                        equipment = "Vision3"
                    break
    except Exception:
        equipment = "Vision3"
        test_program = None
    return equipment, test_program


# ============================================
# 3. í•œ íŒŒì¼ ì²˜ë¦¬ (ë©€í‹°í”„ë¡œì„¸ìŠ¤ì—ì„œ í˜¸ì¶œ)
# ============================================
def process_one_file(args):
    """
    args: (full_path_str, mid, folder_date, gb)
    """
    full_path_str, mid, folder_date, gb = args
    p = Path(full_path_str)
    stem = p.stem
    length = len(stem)
    char18 = stem[17] if length >= 18 else ""

    # ì„¤ë¹„ ë¶„ë¥˜
    if mid in FCT_MAP:
        equipment, tp = FCT_MAP[mid], None
    elif mid == "Vision03":
        equipment, tp = classify_vision_equipment(p)
    else:
        equipment, tp = mid, None

    # --------------------------
    # c) íŒŒì¼ëª… ê¸¸ì´ ê²€ì¦
    # --------------------------
    length_reason = None
    if length < 18:
        length_reason = "íŒŒì¼ëª… ê¸¸ì´<18 â†’ ì˜ëª»ëœ íŒŒì¼ëª…"
    else:
        if char18 in ("C", "1"):
            if length != 51:
                length_reason = f"18ë²ˆì§¸={char18} â†’ ê¸¸ì´ 51 ì•„ë‹˜(í˜„ì¬ {length})"
        elif char18 == "J":
            if length not in (51, 53):
                length_reason = f"18ë²ˆì§¸=J â†’ ê¸¸ì´ 51/53 ì•„ë‹˜({length})"
            else:
                if length == 53 and (len(stem) < 47 or stem[46] != "R"):
                    length_reason = "ê¸¸ì´ 53ì¸ë° 47ë²ˆì§¸ ê¸€ì R ì•„ë‹˜"
        elif char18 in ("P", "N"):
            if length != 52:
                length_reason = f"18ë²ˆì§¸={char18} â†’ ê¸¸ì´ 52 ì•„ë‹˜({length})"
        elif char18 == "S":
            if length not in (52, 54):
                length_reason = f"18ë²ˆì§¸=S â†’ ê¸¸ì´ 52/54 ì•„ë‹˜({length})"
            else:
                if length == 54 and (len(stem) < 48 or stem[47] != "R"):
                    length_reason = "ê¸¸ì´ 54ì¸ë° 48ë²ˆì§¸ ê¸€ì R ì•„ë‹˜"
        else:
            length_reason = f"18ë²ˆì§¸ ê¸€ì ê·œì¹™ ì™¸({char18})"

    # --------------------------
    # d) ë‚ ì§œ ë¹„êµ
    # --------------------------
    date_reason = None
    name_date = ""
    try:
        if length in (51, 53):
            name_date = stem[31:39]
        elif length in (52, 54):
            name_date = stem[32:40]
        else:
            date_reason = "[ë‚ ì§œ] ê¸¸ì´ ê·œì¹™ ë²—ì–´ë‚˜ ë‚ ì§œ ì¶”ì¶œë¶ˆê°€"

        if not date_reason:
            file_date = datetime.strptime(name_date, "%Y%m%d").date()
            folder_date_dt = datetime.strptime(folder_date, "%Y%m%d").date()

            day_diff = (file_date - folder_date_dt).days
            if day_diff not in (-1, 0, 1):
                date_reason = (
                    f"[ë‚ ì§œ] íŒŒì¼={file_date} / í´ë”={folder_date_dt} "
                    f"(ì°¨ì´ {day_diff}ì¼)"
                )
    except Exception:
        if not date_reason:
            date_reason = f"[ë‚ ì§œ] ë‚ ì§œ íŒŒì‹± ì˜¤ë¥˜({name_date})"

    # ê²½ë¡œ ë¼ë²¨
    path_label = f"{equipment}\\{folder_date}\\{gb}"

    # historyìš© í•œ í–‰
    history_row = {
        "full_path": full_path_str,
        "equipment": equipment,
        "date_folder": folder_date,
        "good_bad": gb,
        "filename": p.name,
        "processed_at": datetime.now(),
    }

    # detailìš© í–‰ ëª©ë¡
    detail_rows = []
    if length_reason:
        detail_rows.append(
            {
                "path_label": path_label,
                "filename": p.name,
                "reason": "[ê¸¸ì´] " + length_reason,
            }
        )
    if date_reason:
        detail_rows.append(
            {
                "path_label": path_label,
                "filename": p.name,
                "reason": date_reason,
            }
        )

    return {
        "history_row": history_row,
        "equipment": equipment,
        "detail_rows": detail_rows,
    }


# ============================================
# 4. ë°°ì¹˜ ì²˜ë¦¬
# ============================================
def process_batch(pool, file_infos, conn, equip_counts, run_started_at):
    """
    file_infos: [(full_path_str, mid, folder_date_str, gb), ...]
    """
    if not file_infos:
        return 0, 0

    batch_finished_at = datetime.now()
    results = pool.map(process_one_file, file_infos)

    history_rows = []
    detail_rows = []

    for item in results:
        h = item["history_row"]
        history_rows.append(h)

        eq = item["equipment"]
        equip_counts[eq] = equip_counts.get(eq, 0) + 1

        for d in item["detail_rows"]:
            detail_rows.append(
                {
                    "run_started_at": run_started_at,
                    "run_finished_at": batch_finished_at,
                    "path_label": d["path_label"],
                    "filename": d["filename"],
                    "reason": d["reason"],
                }
            )

    n_hist = insert_history_rows(conn, history_rows)
    n_det = insert_detail_rows(conn, detail_rows)

    return n_hist, n_det


# ============================================
# 5. í•œ ë²ˆ ì‹¤í–‰(run_once)
# ============================================
def run_once():
    run_started_at = datetime.now()
    print("\n==================== run_once ì‹œì‘ ====================")
    print(f"ì‹œê°: {run_started_at}")

    # í˜„ì¬ ê¸°ì¤€ 6ê°œì›” ìœˆë„ìš° ê³„ì‚°
    window_start_date, window_end_date = get_window_dates()
    print(f"[ìœˆë„ìš°] ìŠ¤ìº”/ë³´ê´€ ê¸°ê°„: {window_start_date} ~ {window_end_date}")

    conn = get_connection()
    try:
        # ìŠ¤í‚¤ë§ˆ / í…Œì´ë¸” ìƒì„±
        init_db(conn)

        total_scanned = 0
        total_new = 0
        total_hist_inserted = 0
        total_det_inserted = 0
        equip_counts = {}

        # ğŸ”¥ CPU ì½”ì–´ ê¸°ë°˜ì´ ì•„ë‹ˆë¼ "ê³ ì • 2ê°œ"ë¡œ ê°•ì œ
        cpu_cnt = 2
        print(f"[ë©€í‹°í”„ë¡œì„¸ìŠ¤] ì‚¬ìš© í”„ë¡œì„¸ìŠ¤ ìˆ˜: {cpu_cnt}")

        window_start_str = window_start_date.strftime("%Y%m%d")
        window_end_str = window_end_date.strftime("%Y%m%d")

        # ğŸ”¥ multiprocessing Pool = 2ê°œ
        with mp.Pool(processes=cpu_cnt) as pool:
            batch = []

            for mid in MIDDLE_FOLDERS:
                mid_path = BASE_LOG_DIR / mid
                if not mid_path.exists():
                    print(f"[SKIP] {mid_path} ì—†ìŒ")
                    continue

                for date_folder in sorted(mid_path.iterdir()):
                    if not date_folder.is_dir():
                        continue

                    folder_date_str = date_folder.name

                    # yyyymmdd í˜•ì‹ ì²´í¬
                    if len(folder_date_str) != 8 or not folder_date_str.isdigit():
                        continue

                    # í´ë” ë‚ ì§œê°€ ìœˆë„ìš° ë²”ìœ„ ì•ˆì— ìˆëŠ”ì§€ ì²´í¬
                    if not (window_start_str <= folder_date_str <= window_end_str):
                        continue

                    for gb in TARGET_FOLDERS:
                        gb_path = date_folder / gb
                        if not gb_path.exists():
                            continue

                        for f in gb_path.iterdir():
                            if not f.is_file():
                                continue

                            total_scanned += 1
                            full_path_str = str(f)

                            batch.append((full_path_str, mid, folder_date_str, gb))
                            total_new += 1

                            if len(batch) >= BATCH_SIZE:
                                print(f"[ë°°ì¹˜ ì²˜ë¦¬] {len(batch)}ê°œ íŒŒì¼ ì²˜ë¦¬ ì‹œì‘...")
                                n_hist, n_det = process_batch(
                                    pool,
                                    batch,
                                    conn,
                                    equip_counts,
                                    run_started_at,
                                )

                                total_hist_inserted += n_hist
                                total_det_inserted += n_det
                                print(
                                    f"[ë°°ì¹˜ ì²˜ë¦¬] history {n_hist}ê±´, "
                                    f"detail {n_det}ê±´ ì €ì¥ ì™„ë£Œ."
                                )
                                batch = []

            # ë‚¨ì€ ë°°ì¹˜ ì²˜ë¦¬
            if batch:
                print(f"[ë°°ì¹˜ ì²˜ë¦¬] ë§ˆì§€ë§‰ {len(batch)}ê°œ íŒŒì¼ ì²˜ë¦¬ ì‹œì‘...")
                n_hist, n_det = process_batch(
                    pool,
                    batch,
                    conn,
                    processed_full_paths,
                    equip_counts,
                    run_started_at,
                )
                total_hist_inserted += n_hist
                total_det_inserted += n_det
                print(
                    f"[ë°°ì¹˜ ì²˜ë¦¬] history {n_hist}ê±´, "
                    f"detail {n_det}ê±´ ì €ì¥ ì™„ë£Œ."
                )

        run_finished_at = datetime.now()

        print(f"[ìŠ¤ìº”] ì „ì²´ ìŠ¤ìº” íŒŒì¼ ìˆ˜: {total_scanned}")
        print(f"[ìŠ¤ìº”] ì´ë²ˆ ì‹¤í–‰ì—ì„œ ìƒˆë¡œ ì²˜ë¦¬í•œ íŒŒì¼ ìˆ˜: {total_new}")
        print(f"[DB] ëˆ„ì  history ì €ì¥ ê±´ìˆ˜ : {total_hist_inserted}")
        print(f"[DB] ëˆ„ì  detail  ì €ì¥ ê±´ìˆ˜ : {total_det_inserted}")

        # result(ìš”ì•½) í–‰ë“¤ (ì„¤ë¹„ë³„ 1í–‰ì”©)
        result_rows = [
            {
                "run_started_at": run_started_at,
                "run_finished_at": run_finished_at,
                "equipment": eq,
                "file_count": cnt,
            }
            for eq, cnt in equip_counts.items()
        ]
        n_res = insert_result_rows(conn, result_rows)
        print(f"[DB] result  ì €ì¥ ê±´ìˆ˜ : {n_res}")

    finally:
        conn.close()
        print("==================== run_once ì¢…ë£Œ ====================")

# ============================================
# 6. ë©”ì¸ ë£¨í”„
# ============================================
if __name__ == "__main__":
    try:
        while True:
            try:
                run_once()
            except Exception as e:
                print("[ERROR] run_once ì¤‘ ì˜ˆì™¸ ë°œìƒ:", e)

            time.sleep(1)  # 1ì´ˆ ëŒ€ê¸° í›„ ì¬ì‹¤í–‰
    except KeyboardInterrupt:
        print("\nì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤. í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
