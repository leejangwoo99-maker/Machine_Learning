# """
# sparepart í…ìŠ¤íŠ¸ â†’ RDBMS ì—…ë¡œë“œìš© DataFrame ë³€í™˜ (ë©€í‹°í”„ë¡œì„¸ì‹± + ì´ë ¥ + CSV ì €ì¥)
# ---------------------------------------------------------------------------
# ê¸°ëŠ¥:
#   1) C:\Users\user\Desktop\sparepart\ ì•„ë˜ì˜
#      'YY.MM.DD_ì£¼ê°„.txt' / 'YY.MM.DD_ì•¼ê°„.txt' íŒŒì¼ë“¤ì„ ë³‘ë ¬ë¡œ ì²˜ë¦¬í•´ì„œ
#
#      ì»¬ëŸ¼:
#        date (YYYY-MM-DD)
#        shift ("ì£¼ê°„"/"ì•¼ê°„")
#        fct1_mini_b ~ fct4_power
#
#      í˜•íƒœì˜ pandas DataFrame ìƒì„±
#
#   2) ì´ë¯¸ ì²˜ë¦¬í•œ íŒŒì¼ ê²½ë¡œë¥¼ ì´ë ¥ CSVë¡œ ê´€ë¦¬í•´ì„œ, ë‹¤ìŒ ì‹¤í–‰ ì‹œ ì¤‘ë³µ ì²˜ë¦¬ ë°©ì§€
#      - ì´ë ¥ íŒŒì¼: C:\Users\user\Desktop\b1_sparepart_history.csv
#
#   3) ìµœì¢… DataFrameì„ CSVë¡œ ì €ì¥
#      - ê²°ê³¼ íŒŒì¼: C:\Users\user\Desktop\b1_sparepart_usage.csv
# """

from pathlib import Path
from concurrent.futures import ProcessPoolExecutor, as_completed
from typing import List, Dict, Optional, Set
import pandas as pd
import csv

# ====================================================
# 1. ê¸°ë³¸ ì„¤ì • (í•„ìš” ì‹œ ì—¬ê¸°ë§Œ ìˆ˜ì •)
# ====================================================

# sparepart í…ìŠ¤íŠ¸ íŒŒì¼ë“¤ì´ ìˆëŠ” ìƒìœ„ í´ë”
BASE_DIR = Path(r"C:\Users\user\Desktop\sparepart")

# ë©€í‹°í”„ë¡œì„¸ì‹± ì›Œì»¤ ìˆ˜ (ì½”ì–´ ìˆ˜ì— ë§ê²Œ ì¡°ì ˆ, 0 ë˜ëŠ” Noneì´ë©´ ìë™ ê²°ì •)
MAX_WORKERS = 4

# ğŸ”¹ ì´ë ¥ CSV íŒŒì¼ ê²½ë¡œ (ì´ë¯¸ ì²˜ë¦¬í•œ íŒŒì¼ ê²½ë¡œ ê¸°ë¡)
HISTORY_CSV_PATH = Path(r"C:\Users\user\Desktop\b1_sparepart_history.csv")

# ğŸ”¹ ê²°ê³¼ DataFrame CSV ì €ì¥ ê²½ë¡œ
OUTPUT_CSV_PATH = Path(r"C:\Users\user\Desktop\b1_sparepart_usage.csv")

# FCTë³„ ë¶€í’ˆ ì»¬ëŸ¼(ìˆœì„œ ê³ ì •) â€“ 11~26ë²ˆì§¸ ì¤„ì— í•´ë‹¹
SPAREPART_KEYS = [
    "fct1_mini_b",
    "fct1_usb_c",
    "fct1_usb_a",
    "fct1_power",
    "fct2_mini_b",
    "fct2_usb_c",
    "fct2_usb_a",
    "fct2_power",
    "fct3_mini_b",
    "fct3_usb_c",
    "fct3_usb_a",
    "fct3_power",
    "fct4_mini_b",
    "fct4_usb_c",
    "fct4_usb_a",
    "fct4_power",
]

# ì‚¬ëŒì´ ë³´ê¸° ì‰¬ìš´ ë¼ë²¨(íŒŒì¼ ë‚´ìš©ì˜ ì•ë¶€ë¶„ê³¼ ë§¤ì¹­ìš©, ì„ íƒ ì‚¬í•­)
SPAREPART_LABELS = [
    "FCT1 Mini B",
    "FCT1 USB-C",
    "FCT1 USB-A",
    "FCT1 Power",
    "FCT2 Mini B",
    "FCT2 USB-C",
    "FCT2 USB-A",
    "FCT2 Power",
    "FCT3 Mini B",
    "FCT3 USB-C",
    "FCT3 USB-A",
    "FCT3 Power",
    "FCT4 Mini B",
    "FCT4 USB-C",
    "FCT4 USB-A",
    "FCT4 Power",
]


# ====================================================
# 2. ì´ë ¥ ë¡œë“œ / ì €ì¥ í•¨ìˆ˜
# ====================================================
def load_history(history_path: Path) -> Set[str]:
    """ì´ë ¥ CSVì—ì„œ file_path ì»¬ëŸ¼ì„ ì½ì–´ì™€ setìœ¼ë¡œ ë°˜í™˜."""
    if not history_path.exists():
        return set()

    try:
        df_hist = pd.read_csv(history_path, dtype=str)
        if "file_path" not in df_hist.columns:
            return set()
        return set(df_hist["file_path"].dropna().astype(str).tolist())
    except Exception as e:
        print(f"[WARN] ì´ë ¥ íŒŒì¼ ë¡œë“œ ì¤‘ ì˜¤ë¥˜, ì´ë ¥ ë¬´ì‹œ: {e}")
        return set()


def append_history(history_path: Path, new_paths: List[str]) -> None:
    """ìƒˆë¡œ ì²˜ë¦¬í•œ íŒŒì¼ ê²½ë¡œë“¤ì„ ì´ë ¥ CSVì— append."""
    if not new_paths:
        return

    file_exists = history_path.exists()
    history_path.parent.mkdir(parents=True, exist_ok=True)

    with open(history_path, "a", newline="", encoding="utf-8-sig") as f:
        writer = csv.writer(f)
        if not file_exists:
            writer.writerow(["file_path"])
        for p in new_paths:
            writer.writerow([p])


# ====================================================
# 3. íŒŒì¼ëª…ì—ì„œ ë‚ ì§œ/ì£¼ì•¼ê°„ ì¶”ì¶œ í•¨ìˆ˜
#    íŒŒì¼ëª… ì˜ˆ) 25.11.20_ì£¼ê°„.txt / 25.11.20_ì•¼ê°„.txt
# ====================================================
def parse_filename(path: Path):
    """
    íŒŒì¼ëª…ì—ì„œ ë‚ ì§œ(YYYY-MM-DD)ì™€ ì£¼/ì•¼ê°„(ì£¼ê°„/ì•¼ê°„)ì„ ì¶”ì¶œ.

    ë°˜í™˜:
        date_str: "YYYY-MM-DD" í˜•ì‹ ë¬¸ìì—´
        shift: "ì£¼ê°„" ë˜ëŠ” "ì•¼ê°„"
    """
    stem = path.stem  # ì˜ˆ: "25.11.20_ì£¼ê°„"
    try:
        date_part, shift = stem.split("_", 1)
    except ValueError:
        raise ValueError(f"[íŒŒì¼ëª… ì˜¤ë¥˜] 'YY.MM.DD_ì£¼ê°„/ì•¼ê°„.txt' í˜•ì‹ì´ ì•„ë‹˜: {path.name}")

    # YY.MM.DD íŒŒì‹±
    try:
        yy, mm, dd = date_part.split(".")
        year = 2000 + int(yy)  # 25 â†’ 2025 ë¡œ ê°€ì •
        month = int(mm)
        day = int(dd)
    except Exception as e:
        raise ValueError(f"[ë‚ ì§œ íŒŒì‹± ì˜¤ë¥˜] {path.name}: {e}")

    date_str = f"{year:04d}-{month:02d}-{day:02d}"  # ì˜ˆ: 2025-11-20
    return date_str, shift


# ====================================================
# 4. í•œ ê°œ sparepart í…ìŠ¤íŠ¸ íŒŒì¼ íŒŒì‹±
# ====================================================
def parse_sparepart_file(path_str: str) -> Optional[Dict]:
    """
    í…ìŠ¤íŠ¸ íŒŒì¼(YY.MM.DD_ì£¼ê°„/ì•¼ê°„.txt) í•˜ë‚˜ë¥¼ ì½ì–´ì„œ
    ë”•ì…”ë„ˆë¦¬ í•œ í–‰(row)ìœ¼ë¡œ ë³€í™˜.

    ì»¬ëŸ¼:
      - date  : "YYYY-MM-DD"
      - shift : "ì£¼ê°„" ë˜ëŠ” "ì•¼ê°„"
      - fct1_mini_b ~ fct4_power : int (ì†Œëª¨ëŸ‰)

    ì—ëŸ¬ ë°œìƒ ì‹œ None ë°˜í™˜.
    """
    path = Path(path_str)

    try:
        # íŒŒì¼ëª…ì—ì„œ ë‚ ì§œì™€ ì£¼/ì•¼ê°„ ì¶”ì¶œ
        date_str, shift = parse_filename(path)

        # íŒŒì¼ ì½ê¸° (cp949 â†’ utf-8-sig ìˆœìœ¼ë¡œ ì‹œë„)
        try:
            text = path.read_text(encoding="cp949")
        except UnicodeDecodeError:
            text = path.read_text(encoding="utf-8-sig")

        lines = text.splitlines()

        # ìµœì†Œ 26ì¤„ ì´ìƒì¸ì§€ í™•ì¸ (11~26 ë²ˆì§¸ ì¤„ì— ë°ì´í„°)
        if len(lines) < 26:
            print(f"[ë¼ì¸ ë¶€ì¡±] {path.name}: ì´ {len(lines)}ì¤„")
            return None

        # 11ë²ˆì§¸~26ë²ˆì§¸ ì¤„ â†’ 0-base index 10~25
        data_lines = [line.strip() for line in lines[10:26]]

        # ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
        row = {
            "date": date_str,
            "shift": shift,
        }

        # ê° ë¼ì¸ì—ì„œ ìˆ«ì ë¶€ë¶„ íŒŒì‹±
        for i, key in enumerate(SPAREPART_KEYS):
            line = data_lines[i]
            # "FCT1 Mini B: 011" â†’ ":" ê¸°ì¤€ìœ¼ë¡œ split
            if ":" in line:
                label_part, value_part = line.split(":", 1)
                label_part = label_part.strip()
                value_str = value_part.strip()
            else:
                # ì½œë¡ ì´ ì—†ìœ¼ë©´ ì „ì²´ë¥¼ ê°’ìœ¼ë¡œ ë³´ê³  ì²˜ë¦¬
                label_part = ""
                value_str = line.strip()

            # (ì˜µì…˜) ë¼ë²¨ ì²´í¬ â€“ ìˆœì„œê°€ ê¹¨ì§„ ê²½ìš° ê²½ê³  ì¶œë ¥ë§Œ í•˜ê³  ì§„í–‰
            expected_label = SPAREPART_LABELS[i]
            if expected_label not in label_part:
                print(
                    f"[ë¼ë²¨ ê²½ê³ ] {path.name}ì˜ {i+1}ë²ˆì§¸ sparepart ì¤„ "
                    f"ë¼ë²¨ ë¶ˆì¼ì¹˜: ê¸°ëŒ€='{expected_label}', ì‹¤ì œ='{label_part}'"
                )

            # ìˆ«ì ë³€í™˜ (ì•ì— 0ì´ ë¶™ì–´ ìˆì–´ë„ intë¡œ ë³€í™˜)
            try:
                value = int(value_str)
            except ValueError:
                print(
                    f"[ê°’ ê²½ê³ ] {path.name}ì˜ {expected_label} ê°’ì´ ì •ìˆ˜ê°€ ì•„ë‹˜: "
                    f"'{value_str}', 0ìœ¼ë¡œ ì²˜ë¦¬"
                )
                value = 0

            row[key] = value

        return row

    except Exception as e:
        print(f"[ERROR] {path.name} ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
        return None


# ====================================================
# 5. ì „ì²´ í´ë” ìŠ¤ìº” í›„ DataFrame ìƒì„± (ë©€í‹°í”„ë¡œì„¸ì‹± + ì´ë ¥)
# ====================================================
def build_sparepart_df_parallel(base_dir: Path,
                                history_path: Path,
                                max_workers: Optional[int] = None) -> pd.DataFrame:
    """
    base_dir ì•„ë˜ì˜ 'YY.MM.DD_ì£¼ê°„.txt', 'YY.MM.DD_ì•¼ê°„.txt' íŒŒì¼ì„ ëª¨ë‘ ì°¾ì•„
    (ì´ë¯¸ ì²˜ë¦¬í•œ íŒŒì¼ì€ ì´ë ¥ìœ¼ë¡œ ìŠ¤í‚µ) ë©€í‹°í”„ë¡œì„¸ì‹±ìœ¼ë¡œ ë³‘ë ¬ ì²˜ë¦¬ í›„
    pandas DataFrameìœ¼ë¡œ ë°˜í™˜.
    """
    # txt íŒŒì¼ ì „ì²´ ìŠ¤ìº” (í•˜ìœ„ í´ë”ê¹Œì§€ í¬í•¨í•˜ê³  ì‹¶ìœ¼ë©´ rglob("*.txt") ì‚¬ìš©)
    txt_files: List[Path] = sorted(base_dir.glob("*.txt"))

    if not txt_files:
        print(f"[INFO] '{base_dir}' ì•„ë˜ì— .txt íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        return pd.DataFrame()

    # ì´ë ¥ ë¡œë“œ (ì´ë¯¸ ì²˜ë¦¬í•œ íŒŒì¼ ê²½ë¡œ set)
    history_set = load_history(history_path)
    if history_set:
        print(f"[INFO] ì´ë ¥ì— ê¸°ë¡ëœ íŒŒì¼ ìˆ˜: {len(history_set)}ê°œ")
    else:
        print("[INFO] ì´ë ¥ íŒŒì¼ì´ ì—†ê±°ë‚˜ ë¹„ì–´ ìˆìŒ â†’ ëª¨ë“  íŒŒì¼ ì‹ ê·œ ì²˜ë¦¬")

    # ì´ë ¥ì— ì—†ëŠ” íŒŒì¼ë§Œ ëŒ€ìƒ
    targets: List[Path] = [
        p for p in txt_files
        if str(p.resolve()) not in history_set
    ]

    if not targets:
        print("[INFO] ìƒˆë¡œ ì²˜ë¦¬í•  íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. (ëª¨ë‘ ì´ë ¥ì— ì¡´ì¬)")
        return pd.DataFrame()

    print(f"[INFO] ë°œê²¬ëœ í…ìŠ¤íŠ¸ íŒŒì¼ ìˆ˜: {len(txt_files)}ê°œ")
    print(f"[INFO] ì´ë ¥ ì œì™¸ í›„ ì²˜ë¦¬ ëŒ€ìƒ íŒŒì¼ ìˆ˜: {len(targets)}ê°œ")

    rows: List[Dict] = []
    newly_processed_paths: List[str] = []

    # í”„ë¡œì„¸ìŠ¤ í’€ ìƒì„±
    with ProcessPoolExecutor(max_workers=max_workers) as executor:
        # íŒŒì¼ ê²½ë¡œ ë¬¸ìì—´ì„ ë„˜ê²¨ì•¼ pickling ì•ˆì „
        future_to_path = {
            executor.submit(parse_sparepart_file, str(path)): path
            for path in targets
        }

        total = len(future_to_path)
        for i, future in enumerate(as_completed(future_to_path), start=1):
            path = future_to_path[future]
            try:
                result = future.result()
                if result is not None:
                    rows.append(result)
                    newly_processed_paths.append(str(path.resolve()))
                    print(f"  - ({i}/{total}) ì²˜ë¦¬ ì™„ë£Œ: {path.name}")
                else:
                    print(f"  - ({i}/{total}) ì²˜ë¦¬ ì‹¤íŒ¨/ë¬´ì‹œ: {path.name}")
            except Exception as e:
                print(f"[ERROR] {path.name} ì²˜ë¦¬ ì¤‘ ì˜ˆì™¸ ë°œìƒ: {e}")

    if not rows:
        print("[WARN] ìœ íš¨í•œ ì‹ ê·œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return pd.DataFrame()

    # ì‹ ê·œ ì²˜ë¦¬ íŒŒì¼ ì´ë ¥ì„ CSVì— append
    append_history(history_path, newly_processed_paths)
    print(f"[INFO] ì´ë ¥ íŒŒì¼ ì—…ë°ì´íŠ¸ ì™„ë£Œ: {history_path}")

    df = pd.DataFrame(rows)

    # ì»¬ëŸ¼ ìˆœì„œ ì •ë¦¬: date, shift, FCT1~4 Mini B~Power
    ordered_cols = ["date", "shift"] + SPAREPART_KEYS
    df = df[ordered_cols]

    return df


# ====================================================
# 6. ë©”ì¸ ì‹¤í–‰ë¶€
# ====================================================
def main():
    df = build_sparepart_df_parallel(
        BASE_DIR,
        HISTORY_CSV_PATH,
        max_workers=MAX_WORKERS
    )

    print("\n[DataFrame ë¯¸ë¦¬ë³´ê¸° (ìƒìœ„ 5í–‰)]")
    if df.empty:
        print(" â†’ DataFrame ì´ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤.")
        return

    print(df.head())
    print("\n[í–‰/ì—´ ìˆ˜]")
    print(df.shape)

    # ê²°ê³¼ DataFrameì„ CSVë¡œ ì €ì¥
    try:
        OUTPUT_CSV_PATH.parent.mkdir(parents=True, exist_ok=True)
        df.to_csv(OUTPUT_CSV_PATH, index=False, encoding="utf-8-sig")
        print(f"\n[ì™„ë£Œ] DataFrameì„ CSVë¡œ ì €ì¥í–ˆìŠµë‹ˆë‹¤.")
        print(f"       â†’ {OUTPUT_CSV_PATH}")
    except Exception as e:
        print(f"[ERROR] CSV ì €ì¥ ì¤‘ ì˜¤ë¥˜: {e}")

    # ì—¬ê¸°ì„œ ë°”ë¡œ RDBMSë¡œ ì—…ë¡œë“œë„ ê°€ëŠ¥ (ì˜ˆ: PostgreSQL)
    # from sqlalchemy import create_engine
    # engine = create_engine("postgresql+psycopg2://user:password@host:port/dbname")
    # df.to_sql("b1_sparepart_usage", engine, if_exists="append", index=False)


if __name__ == "__main__":
    # ìœˆë„ìš° í™˜ê²½ì—ì„œ ë©€í‹°í”„ë¡œì„¸ì‹± ì‚¬ìš© ì‹œ í•„ìˆ˜
    main()
