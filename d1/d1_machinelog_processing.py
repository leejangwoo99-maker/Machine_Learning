from pathlib import Path
import re
from collections import defaultdict

import pandas as pd


# ================== ì„¤ì • ==================
# ìƒìœ„ ê²½ë¡œ
ROOT_DIR = Path(r"C:\Users\user\Desktop\machinlog")

# ì—‘ì…€ ì €ì¥ ê²½ë¡œ (ë°”íƒ•í™”ë©´\confirm)
OUTPUT_DIR = Path(r"C:\Users\user\Desktop\confirm")

# ì¸ì½”ë”© ì„¤ì •
ENC_FCT_PDI = "cp949"   # FCT / PDI / Main : ANSI ê°€ì • (cp949)
ENC_MAIN = "cp949"
ENC_VISION = "utf-8"

# íŒŒì¼ëª… íŒ¨í„´ (yyyymmdd_FCT1~4 / PDI1~4 / Main / Vision1~2_Machine_Log.txt)
LOG_FILENAME_PATTERN = re.compile(
    r"(?P<date>\d{8})_(?P<tag>FCT[1-4]|PDI[1-4]|Main|Vision[1-2])_Machine_Log\.txt$",
    re.IGNORECASE,
)

# íŠ¹ìˆ˜ë¬¸ì ì¹˜í™˜ íŒ¨í„´ (í•œê¸€/ì˜ë¬¸/ìˆ«ì/ê³µë°±/ì¼ë¶€ ê¸°í˜¸ë§Œ í—ˆìš©, ë‚˜ë¨¸ì§€ëŠ” '_' ì²˜ë¦¬)
SPECIAL_CHAR_PATTERN = re.compile(r"[^0-9A-Za-zê°€-í£\s\[\]\.:/\-_]")


# ================== ìœ í‹¸ í•¨ìˆ˜ ==================
def sanitize_message(msg: str) -> str:
    """íŠ¹ìˆ˜ë¬¸ìë¥¼ '_'ë¡œ ì¹˜í™˜ (í•œê¸€/ì˜ë¬¸/ìˆ«ì/ê³µë°±/ì¼ë¶€ ê¸°í˜¸ë§Œ í—ˆìš©)"""
    return SPECIAL_CHAR_PATTERN.sub("_", msg)


def read_log_file(file_path: Path, encoding: str, source: str, date_str: str) -> pd.DataFrame:
    """
    ë¡œê·¸ íŒŒì¼ í•œ ê°œë¥¼ ì½ì–´ DataFrame ìœ¼ë¡œ ë°˜í™˜.
    - [hh:mi:ss.ss] ì—†ëŠ” í–‰ì€ ì§ì „ ì‹œê°„ ë”°ë¼ê°
    - íŠ¹ìˆ˜ë¬¸ì '_' ë¡œ ì¹˜í™˜
    """
    records = []
    current_time = None

    with file_path.open("r", encoding=encoding, errors="replace") as f:
        for raw_line in f:
            line = raw_line.rstrip("\n").rstrip("\r")

            # [hh:mi:ss.ss] íŒ¨í„´ íŒŒì‹±
            m = re.match(r"\[(\d{2}:\d{2}:\d{2}\.\d{2})\]\s*(.*)", line)
            if m:
                current_time = m.group(1)
                message = m.group(2)
            else:
                # ì‹œê°„ ì •ë³´ê°€ ì—†ìœ¼ë©´ ì´ì „ ì‹œê°„ ìœ ì§€
                message = line

            if current_time is None:
                # íŒŒì¼ ë§¨ ì•ì— ì‹œê°„ ì—†ëŠ” ì´ìƒ ì¼€ì´ìŠ¤ëŠ” ê·¸ëƒ¥ ìŠ¤í‚µ
                continue

            message_clean = sanitize_message(message)

            records.append(
                {
                    "date": date_str,
                    "time": current_time,
                    "source": source,
                    "message": message_clean,
                    "file_path": str(file_path),
                }
            )

    if not records:
        return pd.DataFrame(columns=["date", "time", "source", "message", "file_path"])

    df = pd.DataFrame(records)
    # ì‹œê°„ ì •ë ¬ìš© ì»¬ëŸ¼
    df["time_sort"] = pd.to_timedelta(df["time"])
    return df


def collect_all_files(root_dir: Path):
    # """
    # ROOT_DIR ì•„ë˜ FCT / Main / Vision í´ë”ì˜ yyyy\mm\ íŒŒì¼ë“¤ì„ ìŠ¤ìº”í•˜ì—¬
    # ë‚ ì§œë³„ / ì¢…ë¥˜ë³„ ê²½ë¡œ ì¸ë±ìŠ¤ë¥¼ ë§Œë“ ë‹¤.
    # """
    index = defaultdict(lambda: {"FCT": {}, "PDI": {}, "Main": None, "Vision": {}})

    total_files = 0
    total_fct = 0
    total_pdi = 0
    total_main = 0
    total_vision = 0

    for mid in ["FCT", "Main", "Vision"]:
        mid_path = root_dir / mid
        if not mid_path.exists():
            print(f"[SKIP] ì¤‘ê°„ í´ë” ì—†ìŒ: {mid_path}")
            continue

        # yyyy\mm ì•„ë˜ ëª¨ë“  íŒŒì¼ ê²€ìƒ‰
        for year_dir in mid_path.iterdir():
            if not year_dir.is_dir():
                continue
            for month_dir in year_dir.iterdir():
                if not month_dir.is_dir():
                    continue
                for file_path in month_dir.iterdir():
                    if not file_path.is_file():
                        continue

                    m = LOG_FILENAME_PATTERN.search(file_path.name)
                    if not m:
                        continue

                    date_str = m.group("date")
                    tag = m.group("tag")

                    total_files += 1
                    t_lower = tag.lower()

                    if t_lower.startswith("fct"):
                        idx = int(tag[-1])
                        index[date_str]["FCT"][idx] = file_path
                        total_fct += 1
                    elif t_lower.startswith("pdi"):
                        idx = int(tag[-1])
                        index[date_str]["PDI"][idx] = file_path
                        total_pdi += 1
                    elif t_lower == "main":
                        index[date_str]["Main"] = file_path
                        total_main += 1
                    elif t_lower.startswith("vision"):
                        idx = int(tag[-1])
                        index[date_str]["Vision"][idx] = file_path
                        total_vision += 1

    print("\n====== íŒŒì¼ ìŠ¤ìº” ê²°ê³¼ ======")
    print(f"ì´ íŒŒì¼ ìˆ˜          : {total_files}")
    print(f"  FCT íŒŒì¼ ìˆ˜       : {total_fct}")
    print(f"  PDI íŒŒì¼ ìˆ˜       : {total_pdi}")
    print(f"  Main íŒŒì¼ ìˆ˜      : {total_main}")
    print(f"  Vision íŒŒì¼ ìˆ˜    : {total_vision}")
    print("==========================\n")

    return index


# ---------- Error ì»¬ëŸ¼ ìƒì„± ----------
def add_error_column(df: pd.DataFrame) -> pd.DataFrame:
    """
    Error ì»¬ëŸ¼ ì¶”ê°€
    ê·œì¹™:
      1) '[BARCODE: ]' â†’ 'ê²°ì¸¡ì¹˜'
      2) ë©”ì‹œì§€ì— '_ìˆ«ì' â†’ 'Tray_ìˆ«ìë¡œ ìˆ˜ì •'
      3) 'ë°”ì½”ë“œ ON' í¬í•¨ â†’ 'Barcode ì‚­ì œ'
      4) [BARCODE: ë‚´ìš©] ì´ ë“¤ì–´ê°„ ë©”ì‹œì§€ê°€ ë™ì¼ ë‚´ìš©ìœ¼ë¡œ ì—¬ëŸ¬ ë²ˆ ë‚˜ì˜¤ë©´ â†’ 'Barcode ë°˜ë³µ'
      5) ì—¬ëŸ¬ ì—ëŸ¬ê°€ ê²¹ì³ë„ ì¤‘ë³µ ì—†ì´ 'ì—ëŸ¬1; ì—ëŸ¬2' í˜•ì‹ìœ¼ë¡œ í‘œê¸°
    """
    if df.empty:
        df["Error"] = ""
        return df

    df = df.copy()

    messages = df["message"].fillna("")
    n = len(df)
    errors_per_row = [[] for _ in range(n)]

    barcode_empty_pattern = re.compile(r"\[BARCODE:\s*\]")
    tray_pattern = re.compile(r"_(\d+)")
    barcode_with_value_pattern = re.compile(r"\[BARCODE:\s*([^\]]+)\]")

    # 1, 2, 3ë²ˆ ê·œì¹™
    for i, msg in enumerate(messages):
        # 1) BARCODE ê²°ì¸¡ì¹˜
        if barcode_empty_pattern.search(msg):
            errors_per_row[i].append("ê²°ì¸¡ì¹˜")

        # 2) _ìˆ«ì â†’ Tray_xë¡œ ìˆ˜ì •
        m_tray = tray_pattern.search(msg)
        if m_tray:
            tray_no = m_tray.group(1)
            errors_per_row[i].append(f"Tray_{tray_no}ë¡œ ìˆ˜ì •")

        # 3) 'ë°”ì½”ë“œ ON' í¬í•¨
        if "ë°”ì½”ë“œ ON" in msg:
            errors_per_row[i].append("Barcode ì‚­ì œ")

    # 4) ë™ì¼ ë‚´ìš© ë°˜ë³µ(Barcode í¬í•¨ ë©”ì‹œì§€ë§Œ)
    mask_barcode_val = messages.str.contains(r"\[BARCODE:\s*[^\]]+\]", regex=True)
    # BARCODE ê°’ì´ ìˆëŠ” ë©”ì‹œì§€ë§Œ ëŒ€ìƒìœ¼ë¡œ value_counts
    barcode_msgs = messages[mask_barcode_val]
    dup_counts = barcode_msgs.value_counts()
    duplicated_msgs = set(dup_counts[dup_counts > 1].index)

    if duplicated_msgs:
        for i, msg in enumerate(messages):
            if msg in duplicated_msgs:
                errors_per_row[i].append("Barcode ë°˜ë³µ")

    # ì¤‘ë³µ ì œê±° í›„ ë¬¸ìì—´ë¡œ í•©ì¹˜ê¸°
    error_strings = []
    for err_list in errors_per_row:
        if not err_list:
            error_strings.append("")
        else:
            seen = set()
            unique_ordered = []
            for e in err_list:
                if e not in seen:
                    seen.add(e)
                    unique_ordered.append(e)
            error_strings.append("; ".join(unique_ordered))

    df["Error"] = error_strings
    return df


def build_daily_datasets(date_str: str, info: dict):
    """
    í•œ ë‚ ì§œ(date_str)ì— ëŒ€í•´
    - FCT1~4 + PDI1~4 ë³‘í•© (PDI ì†ŒìŠ¤ëŠ” FCTë¡œ í‘œì‹œ)
    - Main / Vision1 / Vision2 ë‚´ìš© ë¶„ë¦¬
    - ë‘ ê°œì˜ DataFrame ë°˜í™˜
      A: Main_FCT1,2_Vision1_FVI1
      B: Main_FCT3,4_Vision2_FVI2
    """
    # ===== Main =====
    main_path = info.get("Main")
    main_df = pd.DataFrame(columns=["date", "time", "source", "message", "file_path"])
    if main_path is not None:
        main_df = read_log_file(main_path, ENC_MAIN, "Main", date_str)

    # Aìš© Main í‚¤ì›Œë“œ / Bìš© Main í‚¤ì›Œë“œ
    keywords_a_main = [
        "UP1",
        "UP-BUFFER1",
        "UP2",
        "UP2-1",
        "FCT1",
        "FCT2",
        "VISION1",
        "FVI1",
        "FCT FAIL CV 1",
        "VISION FAIL CV1",
    ]

    keywords_b_main = [
        "UP3",
        "UP4",
        "UP-BUFFER2",
        "UP5",
        "FCT3",
        "FCT4",
        "VISION2",
        "FVI2",
        "FCT FAIL CV 2",
        "VISION FAIL CV2",
    ]

    def filter_by_keywords(df, keywords):
        if df.empty:
            return df
        pattern = "|".join(re.escape(k) for k in keywords)
        return df[df["message"].str.contains(pattern, na=False)]

    main_a = filter_by_keywords(main_df, keywords_a_main)
    main_b = filter_by_keywords(main_df, keywords_b_main)

    # ===== FCT + PDI ë³‘í•© =====
    fct_merged = {}  # idx: DataFrame
    for idx in range(1, 5):
        df_list = []

        fct_path = info["FCT"].get(idx)
        if fct_path is not None:
            df_list.append(
                read_log_file(fct_path, ENC_FCT_PDI, f"FCT{idx}", date_str)
            )

        pdi_path = info["PDI"].get(idx)
        if pdi_path is not None:
            # â˜… PDIë„ sourceë¥¼ FCTë¡œ ë§ì¶°ì„œ í‘œì‹œ â˜…
            df_list.append(
                read_log_file(pdi_path, ENC_FCT_PDI, f"FCT{idx}", date_str)
            )

        if df_list:
            df = pd.concat(df_list, ignore_index=True)
            df.sort_values("time_sort", inplace=True)
            fct_merged[idx] = df
        else:
            fct_merged[idx] = pd.DataFrame(
                columns=["date", "time", "source", "message", "file_path", "time_sort"]
            )

    # A: FCT1,2 / B: FCT3,4
    fct_a_list = [fct_merged[idx] for idx in (1, 2) if not fct_merged[idx].empty]
    fct_b_list = [fct_merged[idx] for idx in (3, 4) if not fct_merged[idx].empty]

    fct_a = (
        pd.concat(fct_a_list, ignore_index=True)
        if fct_a_list
        else pd.DataFrame(columns=main_df.columns)
    )
    fct_b = (
        pd.concat(fct_b_list, ignore_index=True)
        if fct_b_list
        else pd.DataFrame(columns=main_df.columns)
    )

    # ===== Vision =====
    vision1_path = info["Vision"].get(1)
    vision2_path = info["Vision"].get(2)

    vision1_df = pd.DataFrame(
        columns=["date", "time", "source", "message", "file_path", "time_sort"]
    )
    vision2_df = pd.DataFrame(
        columns=["date", "time", "source", "message", "file_path", "time_sort"]
    )

    if vision1_path is not None:
        vision1_df = read_log_file(vision1_path, ENC_VISION, "Vision1", date_str)
    if vision2_path is not None:
        vision2_df = read_log_file(vision2_path, ENC_VISION, "Vision2", date_str)

    # ===== A/B ë°ì´í„°ì…‹ êµ¬ì„± =====
    df_a_list = [main_a, fct_a, vision1_df]
    df_b_list = [main_b, fct_b, vision2_df]

    df_a_list = [d for d in df_a_list if not d.empty]
    df_b_list = [d for d in df_b_list if not d.empty]

    if df_a_list:
        df_a = pd.concat(df_a_list, ignore_index=True)
        df_a.sort_values("time_sort", inplace=True)
    else:
        df_a = pd.DataFrame(
            columns=["date", "time", "source", "message", "file_path", "time_sort"]
        )

    if df_b_list:
        df_b = pd.concat(df_b_list, ignore_index=True)
        df_b.sort_values("time_sort", inplace=True)
    else:
        df_b = pd.DataFrame(
            columns=["date", "time", "source", "message", "file_path", "time_sort"]
        )

    # time_sort ì œê±°
    if "time_sort" in df_a.columns:
        df_a = df_a.drop(columns=["time_sort"])
    if "time_sort" in df_b.columns:
        df_b = df_b.drop(columns=["time_sort"])

    # Error ì»¬ëŸ¼ ìƒì„±
    df_a = add_error_column(df_a)
    df_b = add_error_column(df_b)

    # file_path ì œê±°
    if "file_path" in df_a.columns:
        df_a = df_a.drop(columns=["file_path"])
    if "file_path" in df_b.columns:
        df_b = df_b.drop(columns=["file_path"])

    # ğŸ”¥ ì—¬ê¸°ì„œ ì»¬ëŸ¼ëª… ë³€ê²½
    df_a = df_a.rename(columns={"Error": "Error or Requirement"})
    df_b = df_b.rename(columns={"Error": "Error or Requirement"})

    return df_a, df_b

def save_daily_excels(date_str: str, df_a: pd.DataFrame, df_b: pd.DataFrame):
    """
    ë‚ ì§œë³„ë¡œ A/B DataFrameì„ ì—‘ì…€ë¡œ ì €ì¥.
    íŒŒì¼ëª…:
      - {yyyymmdd}_Main_FCT1,2_Vision1_FVI1_machinelog.xlsx
      - {yyyymmdd}_Main_FCT3,4_Vision2_FVI2_machinelog.xlsx
    """
    OUTPUT_DIR.mkdir(parents=True, exist_ok=True)

    if df_a is not None and not df_a.empty:
        filename_a = f"{date_str}_Main_FCT1,2_Vision1_FVI1_machinelog.xlsx"
        out_a = OUTPUT_DIR / filename_a
        df_a.to_excel(out_a, index=False)
        print(f"[ì €ì¥] A (Main_FCT1,2_Vision1_FVI1): {out_a}")

    if df_b is not None and not df_b.empty:
        filename_b = f"{date_str}_Main_FCT3,4_Vision2_FVI2_machinelog.xlsx"
        out_b = OUTPUT_DIR / filename_b
        df_b.to_excel(out_b, index=False)
        print(f"[ì €ì¥] B (Main_FCT3,4_Vision2_FVI2): {out_b}")


def main():
    # 1) íŒŒì¼ ìŠ¤ìº” ë° ì¸ë±ìŠ¤ ìƒì„±
    file_index = collect_all_files(ROOT_DIR)

    if not file_index:
        print("ì²˜ë¦¬í•  íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        return

    # 2) ë‚ ì§œë³„ ì²˜ë¦¬
    for date_str in sorted(file_index.keys()):
        info = file_index[date_str]
        print(f"\n===== ë‚ ì§œ {date_str} ì²˜ë¦¬ ì¤‘... =====")

        df_a, df_b = build_daily_datasets(date_str, info)
        save_daily_excels(date_str, df_a, df_b)

    print("\nëª¨ë“  ë‚ ì§œ ì²˜ë¦¬ ì™„ë£Œ!")


if __name__ == "__main__":
    main()
